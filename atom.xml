<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Databuzz&#39;s Tech Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://databuzz-team.github.io/"/>
  <updated>2018-10-28T09:59:20.699Z</updated>
  <id>https://databuzz-team.github.io/</id>
  
  <author>
    <name>Databuzz, Databuzz.team@gmail.com</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>&lt;Deep Learning&gt; An introduction to Deep Learning with Tensorflow(Part-2)</title>
    <link href="https://databuzz-team.github.io/2018/10/24/Basic-deep-learning-tensorflow-for-beginner-2/"/>
    <id>https://databuzz-team.github.io/2018/10/24/Basic-deep-learning-tensorflow-for-beginner-2/</id>
    <published>2018-10-24T01:03:01.000Z</published>
    <updated>2018-10-28T09:59:20.699Z</updated>
    
    <content type="html"><![CDATA[<p>이번 포스트에서는 Tensorflow의 기본 문법에 대해서 알아보자.(Tensorflow설치법에 대해서는 다루지 않을 것)</p><h3 id="1-Dataflow"><a href="#1-Dataflow" class="headerlink" title="1. Dataflow"></a>1. Dataflow</h3><div style="width:40%; float:left;"><img src="https://www.tensorflow.org/images/tensors_flowing.gif"><p style="text-align:center"><a href="https://www.tensorflow.org/guide/graphs" target="_blank" rel="noopener">출처 :Graphs and Sessions</a></p></div><div style="width: 60%; float:right; color: #333;"><a href="https://databuzz-team.github.io/2018/10/22/Basic-deep-learning-tensorflow-for-beginner/">이전 포스트 Part 1</a>에서 이미 다룬 내용이며 개념 설명이라 지루할 수는 있지만, Tensorflow를 사용하기 위해선 꼭 이해해야 하는 부분을 다시 그림과 함께 짧게 설명하고자 하니 꼭 읽어주시길 바란다.옆의 그림은 <strong>Tensorflow</strong> 공식 홈페이지에 가면 나와있는 이미지 파일인데, 정말 직관적으로 Tensorflow의 <strong>Dataflow Graph(Node And Operation)</strong> 를 표현해냈다.먼저 <strong>Tensor</strong> 는 옆에서 보이는 검은 라인이고(영어로는 Edge이지만, 라인이 내겐 더 직관적이라 그렇게 설명한 것), <strong>Operation</strong> 은 노드들, 그림에서 타원들을 의미한다. 즉, Tensor가 Operation으로 들어가서 해당 Operation에서 설정한 연산을 진행하고 다시 Tensor를 Output으로 내보내는 것이다.<br><br><blockquote>필자가 이해한 바대로라면 Tensor나 Operation이라는 낯선 단어들을 사용해서 어렵게 느껴지지만 결국은 함수의 기능을 한다고 봐주면 되겠다. 차이점은 Graph는 선언이고 Session을 통해서 Run을 한다는 것</blockquote><br>물론! 끝은 Output으로 값을 내보내는 것을 목적으로 하는 것은 아니다. 우리의 목적은 <strong>W 가중치</strong> 를 <strong>Update</strong> 하는 것이므로, 마지막에 우리가 <strong>Optimizer</strong> 의 변수로 설정한 <strong>W1, b1, W2, b2 ...</strong> 들이 <strong>Update</strong> 되는 것으로 <strong>Session.run()</strong> 이 종료된다.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(task)</span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure></div><div style="width: 100%; clear:both; color: #333;"><h3>2. Operation의 name과 scope의 간략한 소개</h3>본격적으로 코드에 대해 설명하기 전에 <strong>Debugging</strong> 에 도움이 되는 정보인 Operation name에 대해서 간략하게 살펴만 보자.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">c_0 = tf.constant(<span class="number">0</span>, name=<span class="string">"c"</span>)  <span class="comment"># =&gt; operation 이름은 "c"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 이미 사용된 이름은 자동으로 유니크화 시킨다.</span></span><br><span class="line">c_1 = tf.constant(<span class="number">2</span>, name=<span class="string">"c"</span>)  <span class="comment"># =&gt; operation 이름은 "c_1"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Name scope는 접두사로 붙게되는데 나중에 설명할 Tensorboard에서 확인할 때 훨씬 편리하다.</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"outer"</span>):</span><br><span class="line">  c_2 = tf.constant(<span class="number">2</span>, name=<span class="string">"c"</span>)  <span class="comment"># =&gt; operation 이름은 "outer/c"</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Name scope 아래로는 경로로 계층을 표현한다.</span></span><br><span class="line">  <span class="keyword">with</span> tf.name_scope(<span class="string">"inner"</span>):</span><br><span class="line">    c_3 = tf.constant(<span class="number">3</span>, name=<span class="string">"c"</span>)  <span class="comment"># =&gt; operation 이름은 "outer/inner/c"</span></span><br><span class="line"></span><br><span class="line">  c_4 = tf.constant(<span class="number">4</span>, name=<span class="string">"c"</span>)  <span class="comment"># =&gt; operation 이름은 "outer/c_1"</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">with</span> tf.name_scope(<span class="string">"inner"</span>):</span><br><span class="line">    c_5 = tf.constant(<span class="number">5</span>, name=<span class="string">"c"</span>)  <span class="comment"># =&gt; operation 이름은 "outer/inner_1/c"</span></span><br></pre></td></tr></table></figure><p style="text-align:center; margin:0"><a href="https://www.tensorflow.org/guide/graphs" target="_blank" rel="noopener">출처 :Graphs and Sessions</a></p></div><div style="width: 100%; clear:both; color: #333;"><h3>3. Tensorflow 가장 많이 사용되는 함수들을 알아보자</h3>이 포스트에서는 필자가 많이 사용된다고 생각하는 가장 기본적인 함수들만 작성했는데, 이 외에도 거의 모든 수학 연산은 다 구현되어 있으니 자세한 API는 <a href="https://www.tensorflow.org/api_docs/python/" target="_blank" rel="noopener">링크</a>를 통해서 찾아보도록 하자.<ul><li><h5>tf.placeholder()</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.placeholder(</span><br><span class="line">    dtype,</span><br><span class="line">    shape=<span class="keyword">None</span>,</span><br><span class="line">    name=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><strong>tf.placeholder()</strong> 는 머신러닝에서 무조건 사용하는 함수이며, 구조는 위의 코드에서 보듯 dtype, shape, name으로 이루어져있는데 핵심은 <strong>shape</strong> 이다.<br><br><blockquote>다른 포스트에서 언급하겠지만 tensorflow에서 shape을 이해하는 것은 매우 중요하다.</blockquote><br>예를 들어 집값을 예측하는 모델을 우리가 만들고 있고, 집의 <strong>Feature(특징)</strong> 는 <strong>rooms, is_riverside</strong> 로 이루어져 있다고 하자. 그리고 만약 우리가 최종적으로 사용할 <strong>Feature</strong> 의 수는 위에서 말한 두 가지면 충분하다고 결정했다고 본다면, <strong>Input</strong> 데이터의 <strong>shape</strong> 으로 <strong>[?, 2]</strong>, 즉 컬럼은 2 개로 결정을 한 상태라는 것이다. 하지만, 집의 개수, 즉 데이터의 개수는 많을수록 좋은 것이므로 변동의 여지가 언제나 있는 값일 뿐 아니라 최종적으로 우리가 새로운 데이터를 예측하려 할 때에도 변하는 값이라는 것이다.<br><br>그런 이유에서 <strong>tensorflow</strong> 에서는 <strong>placeholder</strong> 라는 함수를 제공하는 것이며, <strong>Feature(X)</strong> 와 <strong>Label(y)</strong> 은 <strong>placeholder</strong> 를 사용해서 넣어준다. 주의할 점은 <strong>sess.run()</strong> 시에 <strong>feed_dict</strong> 에 꼭 값을 직접 <strong>넣어(feed)</strong> 주어야 한다는 것.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">x_data = np.array([[<span class="number">3</span>, <span class="number">1</span>], [<span class="number">4</span>, <span class="number">0</span>], [<span class="number">5</span>, <span class="number">1</span>]])</span><br><span class="line">y_data = np.array([[<span class="number">120000</span>], [<span class="number">100000</span>], [<span class="number">200000</span>]])</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">2</span>], name=<span class="string">"X"</span>)</span><br><span class="line"><span class="comment"># 이 예제에서는 각 집마다의 가격을 예측하는 것이므로, shape은 [None, 1]이 된 것.</span></span><br><span class="line">y = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">1</span>], name=<span class="string">"y"</span>)</span><br></pre></td></tr></table></figure></li><li><h5>tf.Variable()</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.Variable(&lt;initial-value&gt;, name=&lt;optional-name&gt;)</span><br></pre></td></tr></table></figure>머신러닝을 통해서 구하고자하는 값인 <strong>Weight</strong> 나 <strong>Bias</strong> 와 같은 값은 <strong>tensorflow</strong> 의 <strong>tf.Variable()</strong> 함수를 사용해서 선언해야한다. 구조는 위의 code에서 보듯 아주 단순하며, 보통은 Random하게 초기화하는 경우가 많으므로 행렬곱을 할 상대인 <strong>X</strong> 와 예측 값으로 내보내는 <strong>y</strong> 의 <strong>shape</strong> 을 고려해서 <strong>tf.random_normal()</strong> 을 사용하게 된다.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">W = tf.Variable(tf.random_normal([<span class="number">2</span>, <span class="number">1</span>]), name=<span class="string">'wight'</span>)</span><br><span class="line">b = tf.Variable(tf.random_normal([<span class="number">1</span>]), name=<span class="string">'bias'</span>)</span><br></pre></td></tr></table></figure></li><li><h5>tf.matmul()</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tf.matmul(</span><br><span class="line">    a,</span><br><span class="line">    b,</span><br><span class="line">    transpose_a=<span class="keyword">False</span>,</span><br><span class="line">    transpose_b=<span class="keyword">False</span>,</span><br><span class="line">    adjoint_a=<span class="keyword">False</span>,</span><br><span class="line">    adjoint_b=<span class="keyword">False</span>,</span><br><span class="line">    a_is_sparse=<span class="keyword">False</span>,</span><br><span class="line">    b_is_sparse=<span class="keyword">False</span>,</span><br><span class="line">    name=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>머신러닝에서는 <strong>원소간의 곱(Element-wise multiplication)</strong> 보다는 <strong>행렬곱(Matrix multiplication)</strong> 이 훨씬 많이 쓰이므로 <strong>tf.matmul()</strong> 은 꼭 알아야하는 함수이다.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hypothesis = tf.matmul(X, W) + b</span><br></pre></td></tr></table></figure></li><li><h5>tf.train module</h5>오늘 소개할 마지막은 함수가 아닌 <strong>모듈(Module)</strong> 이다. 아래는 가장 보편적인 <strong>Optimizer</strong> 인 <strong>GradientDescentOptimizer</strong> 로 예를 들었지만, 훨씬 많은 모델들을 <strong>tensorflow</strong> 에서는 제공하고 있으니, 이 외에 필요한 정보는 <a href="https://www.tensorflow.org/api_docs/python/tf/train" target="_blank" rel="noopener">링크</a>에서 확인하도록 하자.<br><br><blockquote><strong>목표 함수(Cost function)</strong> 에 대해서 이 포스트에서는 특별히 다루지 않지만, 다음 포스트들에서 CNN, RNN 등의 알고리즘을 구현하며 설명을 추가하겠다.</blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cost = tf.reduce_mean(tf.square(hypothesis - y))</span><br><span class="line">train = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(cost)</span><br></pre></td></tr></table></figure></li></ul><h3>4. 마무리</h3>이번 포스트는 어려운 내용이 없지만 <strong>tensorflow</strong> 를 공부하며 간단한 모델들을 구현해보며 가장 자주 사용되고 중요하다고 느꼈던 점을 정리해보았는데, 처음 시작하는 사람들에게 꼭 도움이 되길 바란다.<br><br>아래는 가장 간단하게 회귀분석 모델을 구현한 코드이며, 위에서 설명한 개념들을 정말 간단한 예제이긴 하지만, 대략적으로 어떻게 쓰이나 보여주기 위해서 작성해보았다.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">x_data = np.array([[<span class="number">3</span>, <span class="number">1</span>], [<span class="number">4</span>, <span class="number">0</span>], [<span class="number">5</span>, <span class="number">1</span>]])</span><br><span class="line">y_data = np.array([[<span class="number">120000</span>], [<span class="number">100000</span>], [<span class="number">200000</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># hyper parameter</span></span><br><span class="line">lr = <span class="number">0.01</span></span><br><span class="line">n_epoch = <span class="number">2000</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">2</span>], name=<span class="string">"X"</span>)</span><br><span class="line">y = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">1</span>], name=<span class="string">"y"</span>)</span><br><span class="line"></span><br><span class="line">W = tf.Variable(tf.random_normal([<span class="number">2</span>, <span class="number">1</span>]), name=<span class="string">'wight'</span>)</span><br><span class="line">b = tf.Variable(tf.random_normal([<span class="number">1</span>]), name=<span class="string">'bias'</span>)</span><br><span class="line"></span><br><span class="line">hypothesis = tf.matmul(X, W) + b</span><br><span class="line"></span><br><span class="line">cost = tf.reduce_mean(tf.square(hypothesis - y))</span><br><span class="line">train = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(cost)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 변수가 있는 경우에는 초기화를 실행해줘야 한다.</span></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="comment"># train이 반환하는 값은 우리에게 필요없다.</span></span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(n_epoch):</span><br><span class="line">        c, _ = sess.run([cost, train], feed_dict=&#123;X: x_data, y: y_data&#125;)</span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">500</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Step :"</span>, step, <span class="string">"Cost :"</span>, c)</span><br><span class="line">            <span class="comment"># x, y를 임의로 만든거라..</span></span><br><span class="line">            <span class="comment"># 이 부분은 train data를 학습시키는지 확인하는 목적 외에는 없다.</span></span><br><span class="line">            print(sess.run(hypothesis, feed_dict=&#123;X: x_data&#125;))</span><br></pre></td></tr></table></figure></div><h3 id="Related-Posts"><a href="#Related-Posts" class="headerlink" title="Related Posts"></a>Related Posts</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;이번 포스트에서는 Tensorflow의 기본 문법에 대해서 알아보자.(Tensorflow설치법에 대해서는 다루지 않을 것)&lt;/p&gt;
&lt;h3 id=&quot;1-Dataflow&quot;&gt;&lt;a href=&quot;#1-Dataflow&quot; class=&quot;headerlink&quot; tit
      
    
    </summary>
    
      <category term="Danial Nam" scheme="https://databuzz-team.github.io/categories/Danial-Nam/"/>
    
    
      <category term="Machine Learning" scheme="https://databuzz-team.github.io/tags/Machine-Learning/"/>
    
      <category term="Artificial Intelligence" scheme="https://databuzz-team.github.io/tags/Artificial-Intelligence/"/>
    
      <category term="Deep Learning" scheme="https://databuzz-team.github.io/tags/Deep-Learning/"/>
    
      <category term="Tensorflow" scheme="https://databuzz-team.github.io/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>&lt;Deep Learning&gt; An introduction to Deep Learning with Tensorflow(Part-1)</title>
    <link href="https://databuzz-team.github.io/2018/10/22/Basic-deep-learning-tensorflow-for-beginner/"/>
    <id>https://databuzz-team.github.io/2018/10/22/Basic-deep-learning-tensorflow-for-beginner/</id>
    <published>2018-10-22T14:27:01.000Z</published>
    <updated>2018-10-28T05:31:07.221Z</updated>
    
    <content type="html"><![CDATA[<p><br></p><p>최근에 번역한 <a href="https://databuzz-team.github.io/2018/10/15/The-Most-in-Demand-Skills-for-Data-Scientists/">“DATA SCIENTISTS에게 가장 요구되는 기술(SKILLS)들”</a> 글에서 확인했듯, 급부상하는 분야인 Machine Learning에서도 Deep Learning은 우리가 앞으로 이 분야에서 일하자면 꼭 공부해야 한다.</p><p>먼저 간단하게 <strong>Machine Learning</strong> 에 대해서 알아보자.</p><h3 id="Machine-Learning"><a href="#Machine-Learning" class="headerlink" title="Machine Learning?"></a>Machine Learning?</h3><p>사실 역사는 이미 오래된 분야다. 하지만 최근들어서야 급부상하는 이유는 무엇보다도 Computing Power의 성장과 방대한 데이터가 있다는 점이다.</p><p>크게는 지도학습과 비지도학습으로 나뉘는데, 지도학습은 Input과 Output을 알려주고 그 사이에 존재하는 로직을 기계가 학습하도록 하는 것이며, 비지도학습은 Input만 알려주고 데이터가 가진 특징 속에서 스스로 학습해나가는 것을 말한다.</p><p>아래의 영상은 최근에 공개된 영상인데 Deep Learning의 현재 수준이 이미 놀라운 수준임을 알 수 있다.</p><iframe src="https://www.youtube.com/embed/PCBTZh41Ris" width="560" height="315" frameborder="0" allowfullscreen></iframe><p>만약 가장 트렌디한 머신러닝 기술들을 보고싶다면 <a href="https://arxiv.org/" target="_blank" rel="noopener">링크</a>를 확인하는 것이 가장 좋다고한다. 학회에 제출하고 논문이 Accept가 되는데 평균적으로 7개월이 걸리는데, 그 기간이면 이미 새로운 기술이 나오는 상황이라.. 만약 트렌드한 기술을 캐치하자면 꼭 <a href="https://arxiv.org/" target="_blank" rel="noopener">링크</a>에서 확인하자.</p><h3 id="왜-Tensorflow인가"><a href="#왜-Tensorflow인가" class="headerlink" title="왜 Tensorflow인가?"></a>왜 Tensorflow인가?</h3><p>Tensorflow는 Google이 개발한 Library인데, 현재는 가장 사랑을 받고 있는 Library로써, Google 자체에서도 Google Photo, Google Voice Search 등은 모두 Tensorflow를 간접적으로 사용하고 있는 App 들이다.</p><h3 id="Tensorflow-기본-개념"><a href="#Tensorflow-기본-개념" class="headerlink" title="Tensorflow 기본 개념"></a>Tensorflow 기본 개념</h3><blockquote><p>이 부분은 <a href="https://towardsdatascience.com/a-beginner-introduction-to-tensorflow-part-1-6d139e038278" target="_blank" rel="noopener">A beginner introduction to TensorFlow (Part-1)</a>을 번역 정리하였다.</p><ul><li><strong>Tensorflow</strong> 의 Core는 그래프(computational graph)와 Tensor로 이루어져있다.</li><li><strong>Tensor와 Vector의 차이점</strong> 은 Tensor는 크기만 가진경우도 존재한다는 점이다. 즉 Vector는 Tensor의 특수상황이며, 부분집합으로 볼 수 있다.</li><li><strong>Tensor</strong> 는 이해했으니 <strong>Flow</strong> 를 살펴보자. <strong>Flow</strong> 는 computational graph 혹은 단순한 graph라고 볼 수 있다. cyclic한 구조는 아니며, 각 노드(아래 그림에서 동그라미)는 덧셈, 뺄셈 등의 기능을 가지고 있다. <div><img src="https://cdn-images-1.medium.com/max/1600/1*7lklTJQytHz8w7Eeqz5ZhA.png"><span style="font-size:12px; text-align:center; display:block; color: #999;"><a href="https://towardsdatascience.com/a-beginner-introduction-to-tensorflow-part-1-6d139e038278" target="_blank" rel="noopener">출처 : A beginner introduction to TensorFlow (Part-1)</a></span></div></li></ul></blockquote><ul><li><strong>e = (a+b) * (b+1)</strong><br>기능(operation)적인 역할을 해야 하는 모든 연결되는 노드(꼭짓점)은 graph의 시작일 수는 없고, Tensor를 받거나 새로운 Tensor를 생성하는 역할을 한다. 또한, computational graph는 항상 복잡한 계층 구조로 되어있는데, 위의 그림에서도 마찬가지로 표현되어 있듯 a+b는 c로 b+1은 d로 표현될 수 있다.</li><li><p><strong>e = (c)*(d), c = a+b and b = b+1</strong><br>위의 그림에서 명백하게 표현되어있듯 각 노드는 전 노드에 의존적이어서 c는 a, b 없이 나올 수 없고, e는 c, d 없이 나올 수 없다. 단 c, d처럼 같은 계층에 존재하는 노드들은 상호 독립적이다. 이 점은 computational graph를 이해할 때 가장 중요한 부분으로써, <strong>같은 레벨에 있는 노드 c의 경우는 d가 먼저 계산되어야 할 이유가 없고, 평행적으로 실행될 수 있다.</strong></p></li><li><p>위에서 설명한 computational graph의 평행 관계(parallelism)가 가장 중요한 개념이니 꼭 숙지해야 한다. 이 평행 관계의 의미는 c 계산이 끝나지 않았다고, d 계산은 평행적으로 이루어진다는 점이며, tensorflow는 이 부분을 멋지게 해낸다.</p></li></ul><h3 id="Tensorflow-분할-실행"><a href="#Tensorflow-분할-실행" class="headerlink" title="Tensorflow 분할 실행"></a>Tensorflow 분할 실행</h3><div><img src="https://cdn-images-1.medium.com/max/1600/1*cok4bMhTvE93UdGmRblEyw.png"><span style="font-size:12px; text-align:center; display:block; color: #999;"><a href="https://towardsdatascience.com/a-beginner-introduction-to-tensorflow-part-1-6d139e038278" target="_blank" rel="noopener">출처 : A beginner introduction to TensorFlow (Part-1)</a></span></div><ul><li><strong>Tensorflow</strong> 는 여러 기계에 평행적으로 계산을 실행하여 훨씬 빠른 연산을 할 수가 있는데, 따로 설정할 필요 없이 내부적으로 설정이 된다.<blockquote><p>위의 그림에서 왼쪽은 single Tensorflow session을 사용한 경우라서 single worker가 존재하는 것이고, 오른쪽은 multiple workers를 사용한 경우</p></blockquote></li><li>Worker들은 서로 다른 기기에서 독립적으로 연산을 하고 다음 노드에 해당하는 Worker에게 Result를 넘겨준다. 이때, Delay로 인한 성능 저하가 일어날 수 있는데 이는 주로 <strong>Tensor</strong> 의 <strong>Size</strong> 에서 발생하므로 어떤 <strong>자료형</strong> 을 설정할 것인지가 <strong>중요한 문제</strong> 다.</li></ul><h3 id="결론"><a href="#결론" class="headerlink" title="결론"></a>결론</h3><p>이번 Part1 글에서는 Machine Learning과 Tensorflow에 대한 소개를 중점으로 썼고, Part2에서는 Tensorflow의 기본 문법과 MNIST Digit 이미지 분류하는 코딩에 대해서 포스팅하겠다.</p><hr><h3 id="Related-Posts"><a href="#Related-Posts" class="headerlink" title="Related Posts"></a>Related Posts</h3><p><a href="https://towardsdatascience.com/a-beginner-introduction-to-tensorflow-part-1-6d139e038278" target="_blank" rel="noopener">A beginner introduction to TensorFlow (Part-1)</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;최근에 번역한 &lt;a href=&quot;https://databuzz-team.github.io/2018/10/15/The-Most-in-Demand-Skills-for-Data-Scientists/&quot;&gt;“DATA SCIENTISTS에
      
    
    </summary>
    
      <category term="Danial Nam" scheme="https://databuzz-team.github.io/categories/Danial-Nam/"/>
    
    
      <category term="Machine Learning" scheme="https://databuzz-team.github.io/tags/Machine-Learning/"/>
    
      <category term="Artificial Intelligence" scheme="https://databuzz-team.github.io/tags/Artificial-Intelligence/"/>
    
      <category term="Deep Learning" scheme="https://databuzz-team.github.io/tags/Deep-Learning/"/>
    
      <category term="Tensorflow" scheme="https://databuzz-team.github.io/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>&lt;Github&gt; Gist를 사용하여 Jupyter Notebook 포스팅하기</title>
    <link href="https://databuzz-team.github.io/2018/10/21/Github-Gist/"/>
    <id>https://databuzz-team.github.io/2018/10/21/Github-Gist/</id>
    <published>2018-10-21T13:01:32.000Z</published>
    <updated>2018-10-23T03:36:33.206Z</updated>
    
    <content type="html"><![CDATA[<h5 id="Gist를-사용하면-아래처럼-소스코드를-임베딩-할-수-있다"><a href="#Gist를-사용하면-아래처럼-소스코드를-임베딩-할-수-있다" class="headerlink" title="Gist를 사용하면 아래처럼 소스코드를 임베딩 할 수 있다."></a><a href="https://gist.github.com/" target="_blank" rel="noopener">Gist</a>를 사용하면 아래처럼 소스코드를 임베딩 할 수 있다.</h5><p>아래의 예는 <strong>Jupyter Notebook</strong> 을 임베딩한 것이지만, 이 외에도 .py, .md, .html 등 소스 코드는 다 할 수 있다.</p><script src="https://gist.github.com/DanialDaeHyunNam/afc48b2814cd7798ee7dbaa00e321468.js"></script><p>사용하는 방법은 아래와 같다.</p><h3 id="1-먼저-Gist-사이트로-이동"><a href="#1-먼저-Gist-사이트로-이동" class="headerlink" title="1. 먼저 Gist 사이트로 이동"></a>1. 먼저 <a href="https://gist.github.com/" target="_blank" rel="noopener">Gist</a> 사이트로 이동</h3><p><img src="/images/danial/gist_1.png"><br>위의 사진처럼 코드를 적는 창이 있다. Jupyter Notebook의 경우에는 해당 파일을 <strong>Drag &amp; Drop</strong> 하면 된다.</p><h3 id="2-Indent-Mode를-Spaces에서-Tabs로-변경"><a href="#2-Indent-Mode를-Spaces에서-Tabs로-변경" class="headerlink" title="2. Indent Mode를 Spaces에서 Tabs로 변경"></a>2. Indent Mode를 Spaces에서 Tabs로 변경</h3><p><img src="/images/danial/gist_2.png"><br>이 경우는 <strong>Jupyter Notebook</strong> 을 임베딩하는 경우에만 적용될 수도 있는 사항이니 조심하자.</p><p>필자는 Jupyter Notebook을 처음부터 도전하였는데, Spaces의 경우에는 계속 Render를 실패하기에 이유를 찾아보다가 발견한 방법이다.</p><h3 id="3-Script-Copy"><a href="#3-Script-Copy" class="headerlink" title="3. Script Copy"></a>3. Script Copy</h3><p><img src="/images/danial/gist_3.png"><br>이미지처럼 Embed 옆에 아이콘을 클릭하면 아래처럼 <strong>script</strong> 태그가 복사된다. Markdown 파일이나 HTML에 붙여넣기하면 된다.<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://gist.github.com/&#123;UserId&#125;/&#123;script&#125;.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure></p><h3 id="Tip-1-이후에-다른-소스코드를-포스팅하고자-하면-Add-file이-아닌-New-gist로-새로운-파일들을-추가하면-된다"><a href="#Tip-1-이후에-다른-소스코드를-포스팅하고자-하면-Add-file이-아닌-New-gist로-새로운-파일들을-추가하면-된다" class="headerlink" title="Tip 1) 이후에 다른 소스코드를 포스팅하고자 하면 Add file이 아닌 New gist로 새로운 파일들을 추가하면 된다."></a>Tip 1) 이후에 다른 소스코드를 포스팅하고자 하면 Add file이 아닌 New gist로 새로운 파일들을 추가하면 된다.</h3><p><img src="/images/danial/gist_helper.png"></p><h3 id="Tip-2-이미-Gist에서-정해준-iframe의-크기를-조절하고-싶은-경우에는-아래의-css를-추가해주면-된다"><a href="#Tip-2-이미-Gist에서-정해준-iframe의-크기를-조절하고-싶은-경우에는-아래의-css를-추가해주면-된다" class="headerlink" title="Tip 2) 이미 Gist에서 정해준 iframe의 크기를 조절하고 싶은 경우에는 아래의 css를 추가해주면 된다."></a>Tip 2) 이미 Gist에서 정해준 iframe의 크기를 조절하고 싶은 경우에는 아래의 css를 추가해주면 된다.</h3><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-class">.gist</span>&#123;</span><br><span class="line">  <span class="attribute">max-width</span>: <span class="number">80%</span>;</span><br><span class="line">  <span class="attribute">margin-top</span>: <span class="number">10px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.gist-data</span>&#123;</span><br><span class="line">  <span class="attribute">max-height</span>: <span class="number">300px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.gist</span> <span class="selector-tag">iframe</span><span class="selector-class">.render-viewer</span>&#123;</span><br><span class="line">  <span class="attribute">max-height</span>: <span class="number">260px</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Related-Posts"><a href="#Related-Posts" class="headerlink" title="Related Posts"></a>Related Posts</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h5 id=&quot;Gist를-사용하면-아래처럼-소스코드를-임베딩-할-수-있다&quot;&gt;&lt;a href=&quot;#Gist를-사용하면-아래처럼-소스코드를-임베딩-할-수-있다&quot; class=&quot;headerlink&quot; title=&quot;Gist를 사용하면 아래처럼 소스코드를 임베딩 할 
      
    
    </summary>
    
      <category term="Danial Nam" scheme="https://databuzz-team.github.io/categories/Danial-Nam/"/>
    
    
      <category term="Git" scheme="https://databuzz-team.github.io/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>&lt;Machine Learning&gt; 비대칭 데이터 문제는 어떻게 해결해야 하나?</title>
    <link href="https://databuzz-team.github.io/2018/10/21/Handle-Imbalanced-Data/"/>
    <id>https://databuzz-team.github.io/2018/10/21/Handle-Imbalanced-Data/</id>
    <published>2018-10-21T02:23:13.000Z</published>
    <updated>2018-10-23T07:34:46.842Z</updated>
    
    <content type="html"><![CDATA[<p><br></p><blockquote><p><a href="https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/" target="_blank" rel="noopener">참고 블로그(8 Tactics to Combat Imbalanced Classes in Your Machine Learning Dataset) 링크</a><br><a href="https://machinelearningmastery.com/" target="_blank" rel="noopener">블로거 링크</a></p></blockquote><p>아직 데이터 사이언스에 입문한지 오래되지는 않았지만, 개인 프로젝트로 인스타그램 데이터를 크롤링하여 작업하면서 <strong>비대칭 데이터 문제(Imbalanced Data)</strong> 에 부딪혔다.</p><p>생각해보면 현실세계에서 우리가 예측하고자 하는 클래스가 Uniform하게 분포되어있을 확률은 낮은 것이 당연하다.</p><h3 id="비대칭-데이터란"><a href="#비대칭-데이터란" class="headerlink" title="비대칭 데이터란?"></a>비대칭 데이터란?</h3><p>비대칭 데이터는 일반적으로 분류 문제에서 클래스들이 균일하게 분포하지 않은 문제를 의미한다.</p><p>간단한 예를 들자면, 100개의 과일 사진 중에 사과 사진이 90개, 귤 사진이 10개인 경우다.</p><p>이 경우라면 100개 중에 랜덤하게 뽑은 사진이 무슨 사진인지 맞춰야 한다면 사과라고 말하는 것이 가장 합리적일 것이다. 이것이 비대칭 데이터에서 일어나는 가장 큰 문제점이다.</p><hr><h3 id="비대칭-데이터-문제를-다루는-8가지-전략"><a href="#비대칭-데이터-문제를-다루는-8가지-전략" class="headerlink" title="비대칭 데이터 문제를 다루는 8가지 전략"></a>비대칭 데이터 문제를 다루는 8가지 전략</h3><p>이제 비대칭 문제에 대해서는 이해했을 것이다. 이제 문제를 해결하기 위해 취해야 할 전략(서두에서 링크한 블로그에서 소개한 8가지 전략)을 알아보자.</p><h3 id="1-데이터를-더-모을-수-있나"><a href="#1-데이터를-더-모을-수-있나" class="headerlink" title="1. 데이터를 더 모을 수 있나?"></a>1. 데이터를 더 모을 수 있나?</h3><p>너무 당연한 질문! 더 많은 데이터는 당연히 조금은 더 클래스 대칭적인 결과를 제공할 것이므로..</p><h3 id="2-평가-기준을-바꿔보자"><a href="#2-평가-기준을-바꿔보자" class="headerlink" title="2. 평가 기준을 바꿔보자."></a>2. 평가 기준을 바꿔보자.</h3><p><strong>Accuracy</strong> 는 비대칭 문제에서는 사용하면 안되는 평가 기준이다(<a href="https://en.wikipedia.org/wiki/Accuracy_paradox" target="_blank" rel="noopener">Accuracy Paradox</a>를 참고하자).</p><p>원문 저자는 자신의 포스트 <a href="https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/" target="_blank" rel="noopener">Classification Accuracy is Not Enough: More Performance Measures You Can Use</a> 에서 소개한 평가기준들을 추천했다.</p><ul><li>Confusion Matrix:<br>예측 결과를 테이블 형태로 보여준다.</li><li>Precision:<br>Positive 클래스에 속한다고 출력한 샘플 중 실제로 Positive 클래스에 속하는 샘플 수의 비율</li><li>Recall<br>실제 Positive 클래스에 속한 샘플 중에 Positive 클래스에 속한다고 출력한 표본의 수</li><li>F1 Score<br>정밀도(Precision)과 재현율(Recall)의 가중 조화 평균</li></ul><p>이 외에도</p><ul><li>Kappa(or Cohen’s kappa)<br>Accuracy를 정규화한 값으로 보여준다.</li><li>ROC Curves<br>ROC(Receiver Operator Characteristic) 커브는 클래스 판별 기준값의 변화에 따른 위양성률(fall-out)과 재현율(recall)의 변화를 시각화한 것이다.</li></ul><h3 id="3-데이터셋을-Re-샘플링하자"><a href="#3-데이터셋을-Re-샘플링하자" class="headerlink" title="3. 데이터셋을 Re-샘플링하자."></a>3. 데이터셋을 Re-샘플링하자.</h3><p>데이터 셋을 변형시켜서 전체 클래스의 분포를 균일하게 만드는 방법으로 두 가지 방법이 있다.</p><ol><li>Over-sampling</li><li>Under-sampling</li></ol><p>둘 다 사용해보는 것을 추천한다.</p><p><a href="https://datascienceschool.net/view-notebook/c1a8dad913f74811ae8eef5d3bedc0c3/" target="_blank" rel="noopener">비대칭 데이터 문제</a> &lt;- 이 링크에서 다양한 샘플링 방법을 시각화해서 설명한 자료들이 있으니 확인하자.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 다양한 샘플링 방법을 구현한 파이썬 패키지이다.</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$pip</span> install -U imbalanced-learn</span><br></pre></td></tr></table></figure><h3 id="4-가짜-데이터-샘플을-만들자"><a href="#4-가짜-데이터-샘플을-만들자" class="headerlink" title="4. 가짜 데이터 샘플을 만들자."></a>4. 가짜 데이터 샘플을 만들자.</h3><p>Over sampling의 기법은 가짜 데이터를 더 생성하는 것이니 위의 방법을 좀 더 발전시킨 전략이라고 보면 되겠다.</p><p><strong>Naive Bayes</strong> 알고리즘을 사용할 경우에는 생성도 가능하니 이를 이용하거나, 가장 인기있는 방법인 <strong>SMOTE(Synthetic Minority Over-sampling Technique)</strong> 를 사용하는 것을 추천한다.</p><p>SMOTE는 부족한 클래스의 모조 샘플을 만들어내는 것이다. 이 알고리즘은 2개 이상의 비슷한 객체들을 선택하여 거리를 재고 사이사이 새로운 데이터를 생성해나간다.</p><p>자세한 정보는 <a href="http://www.jair.org/papers/paper953.html" target="_blank" rel="noopener">링크</a>를 확인하자.</p><h3 id="5-다른-Algorithms을-사용해보자"><a href="#5-다른-Algorithms을-사용해보자" class="headerlink" title="5. 다른 Algorithms을 사용해보자."></a>5. 다른 Algorithms을 사용해보자.</h3><p>언제나 그렇듯, 자신이 가장 좋아하는 알고리즘을 모든 문제에 사용하지 않는 것을 추천한다.</p><p><strong>의사 결정 나무(Decision Tree)</strong> 는 비대칭 문제에서 성능이 좋은 경우가 많다.</p><p>C4.5, C5.0, CART and Random Forest 등 다양하게 사용해보는 것을 추천.</p><h3 id="6-모델에-제한을-준다"><a href="#6-모델에-제한을-준다" class="headerlink" title="6. 모델에 제한을 준다."></a>6. 모델에 제한을 준다.</h3><p><strong>Penalized classification(패널티가 있는 분류)</strong> 는 함수를 설정하여 부족한 클래스를 분류하는 것에 오류가 일어나게 만드는 것을 의미한다. 제한사항으로 설정한 함수(패널티 함수)는 부족한 클래스를 분류하는 것에 좀 더 집중을 할 수 있게 한다.</p><blockquote><p>penalized-SVM, penalized-LDA 등 penalized 된 버젼들이 존재한다.<br>그뿐만아니라, 패널라이즈드 모델들을 위해 Framework도 존재하는데, 예를들어 Weka의 <a href="http://weka.sourceforge.net/doc.dev/weka/classifiers/meta/CostSensitiveClassifier.html#CostSensitiveClassifier--" target="_blank" rel="noopener">CostSensitiveClassifier</a>가 있다.</p></blockquote><p>패널티 매트릭스를 만드는 것은 매우 복잡하여, 특정 알고리즘을 써야 하거나 Re-샘플링이 불가능한 경우에 사용하는 것이 좋다.</p><h3 id="7-다른-관점으로-시도하자"><a href="#7-다른-관점으로-시도하자" class="headerlink" title="7. 다른 관점으로 시도하자."></a>7. 다른 관점으로 시도하자.</h3><p>추천하는 방법으로는 <strong>Anomaly Detection</strong>, <strong>Change Detection</strong> 가 있다.</p><ul><li><a href="https://en.wikipedia.org/wiki/Anomaly_detection" target="_blank" rel="noopener">Anomaly Detection</a></li><li><a href="https://en.wikipedia.org/wiki/Change_detection" target="_blank" rel="noopener">Change Detection</a></li></ul><hr><h3 id="결론"><a href="#결론" class="headerlink" title="결론"></a>결론</h3><p>위의 방법들은 당연하게 시행되어야 하는 순서를 보여준다고 생각한다. 조금 허무할 수도 있지만, 결국은 데이터 <strong>사이언티스트(Scientist)</strong> 라는 단어가 의미하듯.. 실험적인 정신을 가지고 다양한 각도에서 도전하고 가장 좋은 결과를 내기 위해 최선을 다해야 한다는 것..</p><hr><h3 id="Related-Posts"><a href="#Related-Posts" class="headerlink" title="Related Posts"></a>Related Posts</h3><p><a href="https://datascienceschool.net/view-notebook/731e0d2ef52c41c686ba53dcaf346f32/" target="_blank" rel="noopener">분류 성능 평가(데이터 사이언스 스쿨)</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-datase
      
    
    </summary>
    
      <category term="Danial Nam" scheme="https://databuzz-team.github.io/categories/Danial-Nam/"/>
    
    
      <category term="Machine Learning" scheme="https://databuzz-team.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>&lt;Medium 블로그 번역&gt; Data Scientists에게 가장 요구되는 기술(Skills)들</title>
    <link href="https://databuzz-team.github.io/2018/10/15/The-Most-in-Demand-Skills-for-Data-Scientists/"/>
    <id>https://databuzz-team.github.io/2018/10/15/The-Most-in-Demand-Skills-for-Data-Scientists/</id>
    <published>2018-10-15T12:28:03.000Z</published>
    <updated>2018-10-23T03:36:47.339Z</updated>
    
    <content type="html"><![CDATA[<p>요즘 글로벌 시장에서 <strong>Data Scientists</strong> 부족으로 난리라고 한다.. 가장 요구되는 기술들이 무엇인지 분석한 기사가 있어서 번역을 통해서 소개하고자 한다 (자세한 내용은 아래의 링크를 통해서 원문을 확인하자).</p><blockquote><p><a href="https://towardsdatascience.com/the-most-in-demand-skills-for-data-scientists-4a4a8db896db" target="_blank" rel="noopener">원문(The Most in Demand Skills for Data Scientists) 링크</a><br><a href="https://towardsdatascience.com/@jeffhale" target="_blank" rel="noopener">저자 Jeff Hale 블로그 링크</a></p></blockquote><p>기사에서는 조사지역은 미국, 키워드는 “Data Scientist”와 “다른 키워드”를 AND 타입으로 검색하여 데이터 사이언티스트와 연관 키워드가 완전히 매칭되는 결과들만을 모아서 조사하였다. 사용한 채용 사이트는 <strong>LinkedIn, Indeed, SimplyHired, Monster, AngelList</strong>로 5가지이다.</p><p>먼저 아래의 그래프를 통해 요구되는 일반적 스킬들에 대해서 알아보자.<br>(그래프를 만드는데 사용된 자료 및 과정은 <a href="https://www.kaggle.com/discdiver/the-most-in-demand-skills-for-data-scientists/" target="_blank" rel="noopener">Jeff Hale Kaggle Kernel</a>을 참고할 것).</p><div><img src="https://cdn-images-1.medium.com/max/800/1*-oG0j_wGSW_9cNNs4_qgFQ.png"><span style="font-size:12px; text-align:center; display:block; color: #999;"><a href="https://towardsdatascience.com/the-most-in-demand-skills-for-data-scientists-4a4a8db896db" target="_blank" rel="noopener">출처 : The Most In Demand Skills For Data Scientists</a></span></div><p>원본 데이터를 통해서 확인해보면 LinkedIn을 제외한 다른 채용사이트들에서는 Analysis의 비중이 더 높았다. 그래서 전체를 Combine한 결과를 보여주는 위의 그래프에서는 Analysis가 가장 비중이 높은 것으로 보이는 것이다.</p><p>원문 저자가 얻은 Insight를 요약하자면,</p><ul><li>Machine Learning은 예측 시스템을 만드는 가장 핵심 기술이므로 가장 요구되는 기술.</li><li>Data Science는 통계 및 Computer Science기술이 필수.</li><li>Communication이 절반에 가까운 잡 포스팅에서 요구되고 있는 점.</li><li>AI, Deep Learning의 빈도수가 높지 않았으나, 이는 Machine Learning의 부분집합이므로 생긴 현상이다.</li><li>Deep Learning의 경우는 점점 더 사용되는 경우가 늘고 있다. 예를 들어 자연어 처리의 경우에도 가장 많이 사용되고 있는 알고리즘은 Deep Learning. <strong>미래에 Deep Learning 스킬이 훨씬 많은 곳에서 요구하게 될 것이며, Machine Learning은 즉 Deep Learning을 의미하게 될 것이라 본다.</strong></li></ul><p>다음으로는 회사가 원하는 <strong>Technology Skills</strong> 에 대해서 살펴보자.</p><div><img src="https://cdn-images-1.medium.com/max/800/1*jnZT4gFAzScOJ_VnYsni0g.png"><span style="font-size:12px; text-align:center; display:block; color: #999;"><a href="https://towardsdatascience.com/the-most-in-demand-skills-for-data-scientists-4a4a8db896db" target="_blank" rel="noopener">출처 : The Most In Demand Skills For Data Scientists</a></span></div><ol><li><strong>Python</strong><br>1위는 Python. 말이 필요 없다.</li><li><strong>R</strong><br>R은 Python과 비중에서 큰 격차를 보이진 않는데, 이는 R이 Python 이전에 Data Science의 필수 언어였기 때문이다. R의 최초 목적은 통계학을 위해서 시작되었고, 아직도 많은 통계학자들에게 사랑을 받는다.</li><li><strong>SQL</strong><br>SQL은 간혹 Data Science 세계에서 무시되는 경우도 있지만, 실제로는 많은 회사에서 요구되며 해당 스킬을 가지고 있으면 채용시장에서 당연히 훨씬 유리하다.</li><li><strong>Hadoop And Spark</strong><br>둘은 모두 Apache에서 제공되는 빅데이터를 위한 Open Source Tool이다.<br>이 두 가지 스킬은 Medium에서나 Tutorial 등이 눈에 띄게 적게 다뤄지고 있다. 지원자(취준) 중에도 앞서 설명한 기술들을 사용하지만 이 두 가지는 못하는 경우가 훨씬 많으므로, Hadoop과 Spark를 할 줄 안다면 채용시장에서 확실히 유리해질 것이다.</li><li><strong>Java and SAS</strong><br>저자는 이 두 가지 스킬이 이렇게 요구되는 사실에 놀랐다. 이 둘은 보통 Data Science 커뮤니티에서 그렇게 주목받고 있지는 않다.</li><li><strong>Tableau</strong><br>Tableau는 분석 플랫폼 및 시각화 도구이며, 사용법이 간편하다. 현재 무료 버젼이 있지만, 데이터를 Private하게 보관하려면 유료이다.</li></ol><p>저자는 만약 <strong>Tableau</strong> 을 사용한 경험이 없다면, Udemy의 <a href="https://www.udemy.com/tableau10/" target="_blank" rel="noopener">Tableau 강의</a> 를 추천했다.</p><p>아래 그래프는 2017년과 2018년을 비교한 것이다.</p><div><img src="https://cdn-images-1.medium.com/max/800/1*iueZKOOBidZtr-FTYyf6QA.png"><span style="font-size:12px; text-align:center; display:block; color: #999;"><a href="https://towardsdatascience.com/the-most-in-demand-skills-for-data-scientists-4a4a8db896db" target="_blank" rel="noopener">출처 : The Most In Demand Skills For Data Scientists</a></span></div><p>전체적으로 비슷하다. 하지만, <strong>R, Hadoop, Java, SAS and Matlab</strong> 의 요구도는 내려가고 있고, <strong>Tableau</strong> 는 확실히 올라가고 있다는 점은 주목할만하다.</p><h4 id="결론-추천-사항들"><a href="#결론-추천-사항들" class="headerlink" title="결론(추천 사항들)"></a>결론(추천 사항들)</h4><ul><li>데이터 분석은 기본, Machine Learning 기술을 높이는데 집중하자.</li><li>Communication 능력에 투자할 것. 추천 책으로는 <a href="https://www.amazon.com/Made-Stick-Ideas-Survive-Others/dp/1400064287" target="_blank" rel="noopener">Made to Stick</a>이 있고, <a href="http://www.hemingwayapp.com" target="_blank" rel="noopener">Hemmingway Editor</a>을 통해서 writing 능력도 키우자.</li><li>Deep Learning 프레임워크들을 마스터하자. Deep Learning 프레임워크을 능숙하게 사용할 수 있어야한다. 저자가 쓴 다른 <a href="https://towardsdatascience.com/deep-learning-framework-power-scores-2018-23607ddf297a" target="_blank" rel="noopener">블로그 글</a>도 참고할 것.</li><li>만약 R과 Python 중에 배울 언어를 고민 중이라면, Python을 선택할 것. 먼저 Python이 능숙하다면 R을 배우는 것을 고려해볼 것(채용시장에서 더 유리할 것이다).</li></ul><p>회사에서 Python을 사용하는 Data Scientist을 구한다는 것은 당연히 Data Science Libraries(<strong>numpy, pandas, scikit-learn, matplotlib 등</strong>)를 다루길 기대하는 것이다.</p><p>만약 Deep learning을 배우고자 한다면, <strong>Keras, FastAI</strong> 를 <strong>TensorFlow or PyTorch</strong> 이전에 시작할 것을 추천한다. Keras 공부를 위한 추천 책은 <a href="https://www.amazon.com/Deep-Learning-Python-Francois-Chollet/dp/1617294438" target="_blank" rel="noopener">Deep Learning with Python</a>이다.</p><p>끝으로 채용사이트는 <strong>LinkedIn</strong>을 추천한다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;요즘 글로벌 시장에서 &lt;strong&gt;Data Scientists&lt;/strong&gt; 부족으로 난리라고 한다.. 가장 요구되는 기술들이 무엇인지 분석한 기사가 있어서 번역을 통해서 소개하고자 한다 (자세한 내용은 아래의 링크를 통해서 원문을 확인하자
      
    
    </summary>
    
      <category term="Danial Nam" scheme="https://databuzz-team.github.io/categories/Danial-Nam/"/>
    
    
      <category term="Data Science" scheme="https://databuzz-team.github.io/tags/Data-Science/"/>
    
      <category term="Tech News" scheme="https://databuzz-team.github.io/tags/Tech-News/"/>
    
  </entry>
  
  <entry>
    <title>sohyun</title>
    <link href="https://databuzz-team.github.io/2018/10/13/sohyun/"/>
    <id>https://databuzz-team.github.io/2018/10/13/sohyun/</id>
    <published>2018-10-13T07:18:26.000Z</published>
    <updated>2018-10-17T03:45:31.168Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Related-Posts"><a href="#Related-Posts" class="headerlink" title="Related Posts"></a>Related Posts</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Related-Posts&quot;&gt;&lt;a href=&quot;#Related-Posts&quot; class=&quot;headerlink&quot; title=&quot;Related Posts&quot;&gt;&lt;/a&gt;Related Posts&lt;/h3&gt;
      
    
    </summary>
    
      <category term="SoHyun Bae" scheme="https://databuzz-team.github.io/categories/SoHyun-Bae/"/>
    
    
  </entry>
  
  <entry>
    <title>test</title>
    <link href="https://databuzz-team.github.io/2018/10/13/test/"/>
    <id>https://databuzz-team.github.io/2018/10/13/test/</id>
    <published>2018-10-13T06:54:30.000Z</published>
    <updated>2018-10-13T07:04:48.252Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Related-Posts"><a href="#Related-Posts" class="headerlink" title="Related Posts"></a>Related Posts</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Related-Posts&quot;&gt;&lt;a href=&quot;#Related-Posts&quot; class=&quot;headerlink&quot; title=&quot;Related Posts&quot;&gt;&lt;/a&gt;Related Posts&lt;/h3&gt;
      
    
    </summary>
    
      <category term="HanJin Hwang" scheme="https://databuzz-team.github.io/categories/HanJin-Hwang/"/>
    
    
  </entry>
  
  <entry>
    <title>&lt;MACHINE LEARNING&gt; CHAPTER1. 한눈에 보는 머신 러닝</title>
    <link href="https://databuzz-team.github.io/2018/10/13/hands-on-chapter1/"/>
    <id>https://databuzz-team.github.io/2018/10/13/hands-on-chapter1/</id>
    <published>2018-10-13T05:34:56.000Z</published>
    <updated>2018-10-28T09:55:53.090Z</updated>
    
    <content type="html"><![CDATA[<p>Hands-On Machine Learning with Scikit-Learn &amp; TensorFlow 책을 읽고 공부하면서 내용을 요약하고 정리한 것입니다.<br><a id="more"></a></p><h3 id="1-1-머신-러닝이란"><a href="#1-1-머신-러닝이란" class="headerlink" title="1.1 머신 러닝이란?"></a>1.1 머신 러닝이란?</h3><blockquote><p>어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다.</p><pre><code>                                     - 톰 미첼(Tom Mitchell, 1997)</code></pre></blockquote><p>위키백과 문서를 모두 내려받는 것 -&gt; 많은 데이터를 갖게 되는 것 : 머신 러닝 X</p><h3 id="1-2-왜-머신-러닝을-사용하는가"><a href="#1-2-왜-머신-러닝을-사용하는가" class="headerlink" title="1.2 왜 머신 러닝을 사용하는가?"></a>1.2 왜 머신 러닝을 사용하는가?</h3><ul><li>기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제 : 하나의 머신러닝 모델이 코드를 간단하고 더 잘 수행되도록 할 수 있습니다.</li><li>전통적인 방식으로는 전혀 해결 방법이 없는 복잡한 문제 : 가장 뛰어난 머신러닝 기법으로 해결 방법을 찾을 수 있습니다.</li><li>유동적인 환경 : 머신러닝 시스템은 새로운 데이터에 적응할 수 있습니다.</li><li>복잡한 문제와 대량의 데이터에서 통찰 얻기</li></ul><h3 id="1-3-머신러닝-시스템의-종류"><a href="#1-3-머신러닝-시스템의-종류" class="headerlink" title="1.3 머신러닝 시스템의 종류"></a>1.3 머신러닝 시스템의 종류</h3><ul><li>사람의 감독 하에 훈련하는 것인지 그렇지 않은 것인지(지도, 비지도, 준지도, 강화 학습)</li><li>실시간으로 점진적인 학습을 하는지 아닌지(온라인 학습과 배치 학습)</li><li>단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인지 아니면 훈련 데이터셋에서 과학자들처럼 패턴을 발견하여 예측 모델을 만드는지(사례 기반 학습과 모델 기반 학습)</li></ul><p>-&gt; 서로 배타적이지 않으며 연결 가능</p><h4 id="1-3-1-지도-학습과-비지도-학습"><a href="#1-3-1-지도-학습과-비지도-학습" class="headerlink" title="1.3.1  지도 학습과 비지도 학습"></a>1.3.1  지도 학습과 비지도 학습</h4><p>학습하는 동안의 감독 형태나 정보량’에 따라 분류</p><h4 id="지도학습-supervised-learning"><a href="#지도학습-supervised-learning" class="headerlink" title="지도학습(supervised learning)"></a>지도학습(supervised learning)</h4><p>-&gt; 훈련데이터에 레이블 포함</p><ul><li>회귀(regression) : <strong>예측 변수</strong><sup>predictor variable</sup>라 부르는 <strong>특성</strong><sup>featrue</sup>(주행거리, 연식, 브랜드 등)을 사용해 중고차 가격 같은 <strong>타깃</strong> 수치를 예측하는 것</li><li>분류 (Classification) : 전형적 지도 학습</li></ul><p>가장 중요한 지도 학습 알고리즘</p><ul><li>k-최근접 이웃 <sup> k-Nearest Neighbors</sup></li><li>선형 회귀 <sup>Linear Regression</sup></li><li>로지스틱 회귀 <sup>Logistic Regression</sup></li><li>서포트 벡터 머신 <sup>Support Vector Machines(SVM)</sup></li><li>결정 트리 <sup>Decision Tree</sup>와 랜덤 포레스트 <sup>Random Forests</sup></li><li>신경망 <sup>Neural networks</sup></li></ul><h4 id="비지도-학습-unsupervised-learning"><a href="#비지도-학습-unsupervised-learning" class="headerlink" title="비지도 학습(unsupervised learning)"></a>비지도 학습(unsupervised learning)</h4><p>-&gt; 훈련데이터에 레이블 미포함</p><p>가장 중요한 비지도 학습 알고리즘</p><ul><li>군집 <sup>clustering</sup><ul><li>k-평균<sup>k-Means</sup></li><li>계층 군집 분석<sup>Hierarchical Cluster Analysis</sup>(HCA)</li><li>기댓값 최대화<sup>Expectation Maximization</sup></li></ul></li><li>시각화<sup>visualization</sup>와 차원 축소<sup>dimensionality reduction</sup><ul><li>주성분 분석<sup>Principal Component Analysis</sup>(PCA)</li><li>커널<sup>kernel</sup>PCA</li><li>지역적 선형 임베딩<sup>Locally-Linear Embedding</sup>(LLE)</li><li>t-SNE<sup>t-distributed Stochastic Neighbor Embedding</sup></li></ul></li><li>연관 규칙 학습<sup>Assiociation rule learning</sup><ul><li>어프라이어리<sup>Apriori</sup></li><li>이클렛<sup>Eclat</sup></li></ul></li></ul><p>시각화<sup>visualization</sup>알고리즘 : 도식화 가능한 2D나 3D 표현 , 가능한 구조 유지<br>차원 축소<sup>dimensionality reduction</sup> : 상관관계가 있는 여러 특성을 하나로 합치는 것  ex) 주행거리, 연식 -&gt; 차의 마모 (<strong>특성 추출</strong>)<br>이상치 탐지<sup>anomaly detection</sup> : 학습 알고리즘 주입 전 데이터셋에 이상한 값을 자동으로 제거<br>연관 규칙 학습<sup>association rule learning</sup> : 대량의 데이터에서 특성 간의 흥미로운 관계</p><h4 id="준지도-학습semisupervised-learning"><a href="#준지도-학습semisupervised-learning" class="headerlink" title="준지도 학습semisupervised learning"></a>준지도 학습<sup>semisupervised learning</sup></h4><p>레이블이 일부만 존재</p><h4 id="강화-학습Reinforcement-Learning"><a href="#강화-학습Reinforcement-Learning" class="headerlink" title="강화 학습Reinforcement Learning"></a>강화 학습<sup>Reinforcement Learning</sup></h4><p>학습하는 시스템을 <strong>에이전트</strong>, 환경을 관찰해서 행동을 실행하고 보상 또는 벌점을 받습니다. 가장 큰 보상을 얻기 위해 <strong>정책</strong><sup>policdy</sup>이라 부르는최상 전략을 스스로 학습합니다.</p><h4 id="1-3-2-배치-학습과-온라인-학습"><a href="#1-3-2-배치-학습과-온라인-학습" class="headerlink" title="1.3.2 배치 학습과 온라인 학습"></a>1.3.2 배치 학습과 온라인 학습</h4><p>입력 데이터의 스트림<sup>stream</sup>으로부터 점진적으로 학습할 수 있는 여부</p><p><strong>배치 학습</strong><sup>batch learning</sup></p><ul><li>가용한 데이터를 모두 사용해 훈련</li><li>제품 시스템에 적용하면 더 이상의 학습없이 실행</li><li>많은 컴퓨팅 자원 필요(CPU, 메모리 공간, 디스크 공간, 디스크 IO, 네트워크 IO 등)</li><li>자원이 제한된 시스템(예 - 스마트폰, 화성 탐사 로버)이 스스로 학습해야 할 때 많은 자원 사용하면 심각한 문제</li></ul><p><strong>온라인 학습</strong><sup>online learning</sup></p><ul><li>데이터를 순차적으로 한 개씩 또는 미니배치<sup>mini-batch</sup>라 부르는 작은 묶음 단위로 주입</li><li>빠른 변화에 스스로 적응해야하는 시스템에 적합, 컴퓨팅 자원이 제한된 경우</li><li>메인 메모리에 들어갈 수 없는 아주 큰 데이터셋을 학습하는 시스템(<strong>외부 메모리</strong><sup>out-of-core</sup> 학습)</li><li>전체 프로세스는 보통 오프라인, 따라서 <strong>점진적 학습</strong><sup>incremental learning</sup>으로 생각</li><li><strong>학습률</strong><sup>learning rate</sup> : 변화는 데이터에 얼마나 빠르게 적응할 것</li></ul><h4 id="1-3-3-사례-기반-학습과-모델-기반-학습"><a href="#1-3-3-사례-기반-학습과-모델-기반-학습" class="headerlink" title="1.3.3 사례 기반 학습과 모델 기반 학습"></a>1.3.3 사례 기반 학습과 모델 기반 학습</h4><p>어떻게 <strong>일반화</strong>되는가에 따라 분류</p><p><strong>사례 기반 학습</strong><sup>instance-based learning</sup></p><ul><li><strong>유사도</strong><sup>similarity</sup>를 측정하여 새로운 데이터를 일반화</li></ul><p><strong>모델 기반 학습</strong><sup>model-based learning</sup></p><ul><li>모델을 만들어 <strong>예측</strong>에 사용<ul><li>데이터를 분석</li><li>모델 선택</li><li>훈련 데이터로 모델 훈련(비용 함수<sup>cost function</sup> 최소화 하는 모델 파라미터 탐색)</li><li>새로운 데이터에 모델을 적용해 예측, 잘 일반화되길 기대</li></ul></li></ul><h3 id="1-4-머신러닝의-주요-도전-과제"><a href="#1-4-머신러닝의-주요-도전-과제" class="headerlink" title="1.4 머신러닝의 주요 도전 과제"></a>1.4 머신러닝의 주요 도전 과제</h3><p>문제점</p><ol><li>나쁜 알고리즘</li><li>나쁜 데이터</li></ol><h4 id="1-4-1-충분하지-않은-양의-훈련-데이터"><a href="#1-4-1-충분하지-않은-양의-훈련-데이터" class="headerlink" title="1.4.1 충분하지 않은 양의 훈련 데이터"></a>1.4.1 충분하지 않은 양의 훈련 데이터</h4><h4 id="1-4-2-대표성-없는-훈련-데이터"><a href="#1-4-2-대표성-없는-훈련-데이터" class="headerlink" title="1.4.2 대표성 없는 훈련 데이터"></a>1.4.2 대표성 없는 훈련 데이터</h4><ul><li>샘플이 작으면 <strong>샘플링 잡음</strong><sup>sampling noise</sup>(즉, 우연에 의한 대표성 없는 데이터)</li><li>샘플이 큰 경우도 추출 방법이 잘못된 경우 <strong>샘플링 편향</strong><sup>sampling bias</sup></li></ul><h4 id="1-4-3-낮은-품질의-데이터"><a href="#1-4-3-낮은-품질의-데이터" class="headerlink" title="1.4.3 낮은 품질의 데이터"></a>1.4.3 낮은 품질의 데이터</h4><ul><li>에러, 이상치<sup>outlier</sup>, 잡음</li><li>이상치가 명확하면 무시하거나 수동으로 잘못된 것을 고침</li><li>일부 특성 중 데이터가 누락된 경우 특성을 무시할지, 샘플을 무시할지, 빠진값을 채울지, 특성을 넣은 모델과 제외한 모델을 따로 훈련 시킬것인지 결정</li></ul><h4 id="1-4-4-관련-없는-특성"><a href="#1-4-4-관련-없는-특성" class="headerlink" title="1.4.4 관련 없는 특성"></a>1.4.4 관련 없는 특성</h4><ul><li><strong>특성 공학</strong><sup>feature engineering</sup> : 훈련에 사용할 좋은 특성들을 찾는 것<ul><li><strong>특성 선택</strong><sup>feature selection</sup> : 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택</li><li><strong>특성 추출</strong><sup>feature extraction</sup> : 특성을 결합하여 더 유용한 특성을 만듬(차원 축소 알고리즘)</li><li>새 특성을 만듬</li></ul></li></ul><h4 id="1-4-5-훈련-데이터-과대적합"><a href="#1-4-5-훈련-데이터-과대적합" class="headerlink" title="1.4.5 훈련 데이터 과대적합"></a>1.4.5 훈련 데이터 과대적합</h4><ul><li><strong>과대적합</strong><sup>overfitting</sup> : 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어짐<ul><li>훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 발생</li><li>파라미터 수가 적은 모델 선택, 훈련데이터에 특성수를 줄임, 모델에 제약을 가하여 단순화(<strong>하이퍼파라미터</strong><sup>hyperparameter</sup> : 학습하는 동안 적용할 규제의 양, 학습 알고리즘의 파라미터)</li><li>훈련 데이터를 더 많이 모음</li><li>훈련 데이터의 잡음을 줄임</li></ul></li></ul><h4 id="1-4-6-훈련-데이터-과소적합"><a href="#1-4-6-훈련-데이터-과소적합" class="headerlink" title="1.4.6 훈련 데이터 과소적합"></a>1.4.6 훈련 데이터 과소적합</h4><ul><li><strong>과소적합</strong><sup>underfitting</sup> : 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때<ul><li>파라미터가 더 많은 강력한 모델 선택</li><li>더 좋은 특성 제공(특성 엔지니어링)</li><li>모델의 제약을 줄임( 규제 하이퍼파라미터를 감소)</li></ul></li></ul><h3 id="1-5-테스트와-검증"><a href="#1-5-테스트와-검증" class="headerlink" title="1.5 테스트와 검증"></a>1.5 테스트와 검증</h3><ul><li><strong>훈련 세트</strong> 와 <strong>테스트 세트</strong> 로 나누어 훈련<ul><li><strong>일반화 오차</strong><sup>generalization error</sup>(<strong>외부 샘플 오차</strong><sup>out-of-sample erro</sup>) : 새로운 샘플에 대한 오류 비율</li><li>훈련 오차가 낮지만 일반화 오차가 높다면 과대 적합</li></ul></li><li><strong>검증 세트</strong><sup>validation set</sup><ul><li><strong>교차 검증</strong><sup>cross-validation</sup> 기법</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Hands-On Machine Learning with Scikit-Learn &amp;amp; TensorFlow 책을 읽고 공부하면서 내용을 요약하고 정리한 것입니다.&lt;br&gt;
    
    </summary>
    
      <category term="HyunGeun Yoon" scheme="https://databuzz-team.github.io/categories/HyunGeun-Yoon/"/>
    
    
      <category term="Machine Learning" scheme="https://databuzz-team.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>&lt;Hexo&gt; 블로그에 수식 사용하기 - mathjax 설정</title>
    <link href="https://databuzz-team.github.io/2018/10/13/hexo-mathjax/"/>
    <id>https://databuzz-team.github.io/2018/10/13/hexo-mathjax/</id>
    <published>2018-10-13T05:30:55.000Z</published>
    <updated>2018-10-28T09:55:53.091Z</updated>
    
    <content type="html"><![CDATA[<p>필자의 개인 블로그에 포스팅한 내용을 가져와 소개합니다. (<a href="https://hyeshinoh.github.io/2018/10/24/hexo_mathjax_00/" target="_blank" rel="noopener">원문 블로그</a>)</p><p>Hexo 블로그에서 LaTex로 수식을 작성할 수 있도록 mathjax를 설정하는 방법을 정리해보겠습니다.</p><h2 id="1-설치"><a href="#1-설치" class="headerlink" title="1. 설치"></a>1. 설치</h2><h3 id="1-renderer-설치-및-세팅"><a href="#1-renderer-설치-및-세팅" class="headerlink" title="1) renderer 설치 및 세팅"></a>1) renderer 설치 및 세팅</h3><p>Hexo의 기본 renderer인 hexo-renderer-marked는 mathjax 문법을 지원하지 않는다고 합니다. 따라서 다음과 같이 새로운 rendering engine으로 교체해줍니다.</p><p><code>$ npm uninstall hexo-renderer-marked --save</code><br><code>$ npm install hexo-renderer-kramed --save</code></p><p>그리고 <code>&lt;your-project-dir&gt;/node_modules/hexo-reneder-kramed/lib/renderer.js</code>를 열어 다음과 같이 return 값을 text로 수정합니다.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Change inline math rule</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">formatText</span>(<span class="params">text</span>) </span>&#123;</span><br><span class="line">  <span class="comment">// Fit kramed's rule: $$ + \1 + $$</span></span><br><span class="line">  <span class="comment">// return text.replace(/`\$(.*?)\$`/g, '$$$$$1$$$$');</span></span><br><span class="line">  <span class="keyword">return</span> text;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-mathjax-설치"><a href="#2-mathjax-설치" class="headerlink" title="2) mathjax 설치"></a>2) mathjax 설치</h3><p>다음으로는 mathjax plugin을 설치합니다.<br><code>npm install hexo-renderer-mathjax --save</code></p><p>그리고 <code>&lt;your-project-dir&gt;/node_modules/hexo-reneder-mathjax/mathjax.html</code>을 열고 CDN URL을 아래와 같이 수정합니다.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- &lt;script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"&gt;&lt;/script&gt; --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="2-LaTex와-markdown의-문법-충돌-fix하기"><a href="#2-LaTex와-markdown의-문법-충돌-fix하기" class="headerlink" title="2. LaTex와 markdown의 문법 충돌 fix하기"></a>2. LaTex와 markdown의 문법 충돌 fix하기</h2><p>LaTex와 markdown에는 다음과 같이 문법이 충돌하는 부분이 있습니다. </p><ul><li>markdown: <code>*</code>과 <code>_</code>는 bold와 italic</li><li>LaTex: <code>_</code>는 subscript</li></ul><p>따라서 <code>_</code>는 LaTex의 문법만을 따라서 아랫첨자를 나타내도록 하기위해<code>node_modules\kramed\lib\rules\inline.js</code>를 열고 다음과 같이 수정합니다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">escape: /^\\([`*\[\]()#$+\-.!_&gt;])/,</span><br><span class="line">em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</span><br></pre></td></tr></table></figure><h2 id="3-Mathjax-사용하기"><a href="#3-Mathjax-사용하기" class="headerlink" title="3. Mathjax 사용하기"></a>3. Mathjax 사용하기</h2><p>사용하고 있는 theme의 <code>_config.yml</code> 파일을 열고 다음과 같이 mathjax를 enabling 해줍니다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mathjax:</span><br><span class="line">  enable: true</span><br></pre></td></tr></table></figure><h2 id="4-markdown-post-작성하기"><a href="#4-markdown-post-작성하기" class="headerlink" title="4. markdown post 작성하기"></a>4. markdown post 작성하기</h2><p>이제 hexo 블로그에 수식을 사용하기 위한 설정은 모두 마쳤습니다.<br>마지막으로 post 작성시 header 부분에 <code>mathjax: true</code>를 넣어주면 블로그에 수식이 잘 표현되게 됩니다.</p><h4 id="참고-자료"><a href="#참고-자료" class="headerlink" title="참고 자료"></a>참고 자료</h4><ul><li>블로그 <a href="https://www.infiniteft.xyz/2018/03/21/make-hexo-support-latex/" target="_blank" rel="noopener">Make Hexo Support Latex</a></li><li>블로그 <a href="https://irongaea.github.io/2018/08/21/hexo-inline-math/" target="_blank" rel="noopener">hexo-inline-math</a></li><li>블로그 <a href="https://johngrib.github.io/wiki/mathjax-latex/#3-%EB%8F%84%EA%B5%AC" target="_blank" rel="noopener">MathJax로 LaTeX 사용하기</a></li><li><a href="https://www.mathjax.org/#gettingstarted" target="_blank" rel="noopener">www.mathjax.org</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;필자의 개인 블로그에 포스팅한 내용을 가져와 소개합니다. (&lt;a href=&quot;https://hyeshinoh.github.io/2018/10/24/hexo_mathjax_00/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;원문 블로그&lt;
      
    
    </summary>
    
      <category term="HyeShin Oh" scheme="https://databuzz-team.github.io/categories/HyeShin-Oh/"/>
    
    
      <category term="Hexo" scheme="https://databuzz-team.github.io/tags/Hexo/"/>
    
      <category term="Mathjax" scheme="https://databuzz-team.github.io/tags/Mathjax/"/>
    
  </entry>
  
  <entry>
    <title>test2</title>
    <link href="https://databuzz-team.github.io/2018/10/11/test2/"/>
    <id>https://databuzz-team.github.io/2018/10/11/test2/</id>
    <published>2018-10-11T11:55:06.000Z</published>
    <updated>2018-10-12T01:30:36.001Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Related-Posts"><a href="#Related-Posts" class="headerlink" title="Related Posts"></a>Related Posts</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Related-Posts&quot;&gt;&lt;a href=&quot;#Related-Posts&quot; class=&quot;headerlink&quot; title=&quot;Related Posts&quot;&gt;&lt;/a&gt;Related Posts&lt;/h3&gt;
      
    
    </summary>
    
      <category term="Haley Jang" scheme="https://databuzz-team.github.io/categories/Haley-Jang/"/>
    
    
  </entry>
  
  <entry>
    <title>test</title>
    <link href="https://databuzz-team.github.io/2018/10/10/test/"/>
    <id>https://databuzz-team.github.io/2018/10/10/test/</id>
    <published>2018-10-10T10:14:21.000Z</published>
    <updated>2018-10-11T01:03:23.621Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Related-Posts"><a href="#Related-Posts" class="headerlink" title="Related Posts"></a>Related Posts</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Related-Posts&quot;&gt;&lt;a href=&quot;#Related-Posts&quot; class=&quot;headerlink&quot; title=&quot;Related Posts&quot;&gt;&lt;/a&gt;Related Posts&lt;/h3&gt;
      
    
    </summary>
    
      <category term="Derrick Kim" scheme="https://databuzz-team.github.io/categories/Derrick-Kim/"/>
    
    
  </entry>
  
  <entry>
    <title>&lt;DataBuzz&gt; 블로그 작성법 및 주의사항</title>
    <link href="https://databuzz-team.github.io/2018/10/10/How-To-Use/"/>
    <id>https://databuzz-team.github.io/2018/10/10/How-To-Use/</id>
    <published>2018-10-10T09:04:34.000Z</published>
    <updated>2018-10-13T07:04:42.780Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Hexo-Scaffolds란"><a href="#Hexo-Scaffolds란" class="headerlink" title="Hexo Scaffolds란?"></a>Hexo Scaffolds란?</h3><p>hexo new -[page/post/draft 등] 을 실행했을 때 Default로 들어갈 정보를 입력하는 공간이다.</p><h3 id="1-Scaffolds-post-md-파일-수정하기"><a href="#1-Scaffolds-post-md-파일-수정하기" class="headerlink" title="1. Scaffolds/post.md 파일 수정하기"></a>1. Scaffolds/post.md 파일 수정하기</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /scaffolds/post.md</span></span><br><span class="line">---</span><br><span class="line">title: &#123;&#123; title &#125;&#125;</span><br><span class="line">date: &#123;&#123; date &#125;&#125;</span><br><span class="line">categories:</span><br><span class="line">  - <span class="string">"Danial Nam"</span> &lt;- 이 부분을 자신의 이름으로 변경한다.</span><br><span class="line">tags:</span><br><span class="line">  -</span><br><span class="line">thumbnail:</span><br><span class="line">---</span><br></pre></td></tr></table></figure><h3 id="2-New-post-추가하기"><a href="#2-New-post-추가하기" class="headerlink" title="2. New post 추가하기"></a>2. New post 추가하기</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new post <span class="string">"제목"</span></span><br></pre></td></tr></table></figure><h3 id="3-Title"><a href="#3-Title" class="headerlink" title="3. Title"></a>3. Title</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Title에는 []를 사용할 경우 오류가난다.</span><br><span class="line">필요시에는 &lt;&gt;로 대체할 것.</span><br></pre></td></tr></table></figure><h3 id="4-Tags"><a href="#4-Tags" class="headerlink" title="4. Tags"></a>4. Tags</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">깔끔한 블로그 관리를 위하여 Tag는 영어 Full Name으로 표기하며,</span><br><span class="line">파스칼케이스를 사용한다.</span><br><span class="line"></span><br><span class="line"><span class="comment"># Depth 및 Indent에 주의할 것!</span></span><br><span class="line">tags:</span><br><span class="line">  - Artificial Intelligence</span><br><span class="line">  - Data Science</span><br><span class="line">  -</span><br><span class="line"></span><br><span class="line">예)</span><br><span class="line">  AI -&gt; Artificial Intelligence</span><br><span class="line">  Data science -&gt; Data Science</span><br></pre></td></tr></table></figure><h3 id="5-Deploy-중요함"><a href="#5-Deploy-중요함" class="headerlink" title="5. Deploy(중요함!!)"></a>5. Deploy(중요함!!)</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sh post.sh</span><br><span class="line"><span class="comment"># 반드시 위의 명령을 실행하여 업로드한다!</span></span><br><span class="line"><span class="comment"># hexo g -d 명령을 사용해서 업로드해서는 안된다!!</span></span><br></pre></td></tr></table></figure><p>마지막에 Git pull해라는 오류가 뜨면, Pull을 실행하고 다시 sh post.sh로 재업로드해줄것!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Hexo-Scaffolds란&quot;&gt;&lt;a href=&quot;#Hexo-Scaffolds란&quot; class=&quot;headerlink&quot; title=&quot;Hexo Scaffolds란?&quot;&gt;&lt;/a&gt;Hexo Scaffolds란?&lt;/h3&gt;&lt;p&gt;hexo new -[page/
      
    
    </summary>
    
      <category term="Danial Nam" scheme="https://databuzz-team.github.io/categories/Danial-Nam/"/>
    
    
      <category term="Data Science" scheme="https://databuzz-team.github.io/tags/Data-Science/"/>
    
  </entry>
  
</feed>
