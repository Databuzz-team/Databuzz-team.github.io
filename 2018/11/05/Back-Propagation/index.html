<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Databuzz, Databuzz.team@gmail.com"><title><Neural Network> 신경망 Feedforward & Back Propagation에 대한 이해 · Databuzz's Tech Blog</title><meta name="description" content="이번 포스트는 TensorFlow로 DNN을 구현하기 전에 먼저 인공 신경망을 가능하게 한 Back Propagation 에 대한 이해를 도울 수 있는 블로그 Back-Propagation is very simple. Who made it Complicated ? 내용"><meta name="keywords" content="DataScience"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/top-image.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/solid.css" integrity="sha384-VGP9aw4WtGH/uPAOseYxZ+Vz/vaTb1ehm1bwx92Fm8dTrE+3boLfF1SpAtB1z7HW" crossorigin="anonymous"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/fontawesome.css" integrity="sha384-1rquJLNOM3ijoueaaeS5m+McXPJCGdr5HcA03/VHXxcp2kX2sUrQDmFc3jR5i/C7" crossorigin="anonymous"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/brands.css" integrity="sha384-rf1bqOAj3+pw6NqYrtaE1/4Se2NBwkIfeYbsFdtiR6TQz0acWiwJbv1IM/Nt/ite" crossorigin="anonymous"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/fontawesome.css" integrity="sha384-1rquJLNOM3ijoueaaeS5m+McXPJCGdr5HcA03/VHXxcp2kX2sUrQDmFc3jR5i/C7" crossorigin="anonymous"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/reset.css"><link rel="stylesheet" href="/css/new.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Luckiest+Guy|Stylish|Boogaloo"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/js/jquery.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js"></script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-127200932-1"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/custom.js"></script><script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/main_logo_new.png" style="width:127px;"><h3 class="sidebar_title" title="">DataBuzz</h3><div class="description"><p class="title_description">Awesome Tech Blog<a class="rss-icon-a" href="https://databuzz-team.github.io/atom" target="__blank"><i class='fas fa-rss rss-icon'></i></a></p></div></div></div><div class="featured-tags-wrap"><h1 class="featured-tags-title">FEATURED TAGS</h1><ul class="featured-tags-ul"><li class="featured-tags-li tag-li-detail"> Data Science </li><li class="featured-tags-li tag-li-detail"> Hexo </li><li class="featured-tags-li tag-li-detail"> Mathjax </li><li class="featured-tags-li tag-li-detail"> Machine Learning </li><li class="featured-tags-li tag-li-detail"> Tech News </li><li class="featured-tags-li tag-li-detail"> Git </li><li class="featured-tags-li tag-li-detail"> Artificial Intelligence </li><li class="featured-tags-li tag-li-detail"> Deep Learning </li><li class="featured-tags-li tag-li-detail"> Tensorflow </li><li class="featured-tags-li tag-li-detail"> Catboost </li><li class="featured-tags-li tag-li-detail"> Back Propagation </li><li class="featured-tags-li tag-li-detail"> Neural Network </li><li class="featured-tags-li tag-li-detail"> Markdown </li><li class="featured-tags-li tag-li-detail"> Regression </li></ul></div><div class="footer"><span>@ 2018 DataBuzz All Rights Reserved</span><br><span>Hexo Theme by </span><a href="https://www.caicai.me"> CaiCai </a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><span>&nbsp;&nbsp;&nbsp; Edited by </span><a href="https://danialdaehyunnam.github.io"> Danial Nam </a></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/"><i class="fas fa-home nav-icon"></i>Home</a></li><li><a href="/archives"><i class="fas fa-archive nav-icon"></i>Archives</a></li><li><a href="/tags-and-authors"><i class="fas fa-user-tag nav-icon"></i>Tags & Authors</a></li><li><a href="/about-us"><i class="fas fa-building nav-icon"></i>About Us</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left back-btn-icon" onclick="window.history.go(-1)"> </a></li></div><div class="avatar"><img src="/images/sun.png"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>&lt;Neural Network&gt; 신경망 Feedforward &amp; Back Propagation에 대한 이해</a></h3></div><div class="post-content post-detail"><p><br></p>
<p>이번 포스트는 TensorFlow로 DNN을 구현하기 전에 먼저 인공 신경망을 가능하게 한 <strong>Back Propagation</strong> 에 대한 이해를 도울 수 있는 <a href="https://medium.com/@14prakash/back-propagation-is-very-simple-who-made-it-complicated-97b794c97e5c?fbclid=IwAR2bn8rI7yxT5BC-0Ovy2IvzHEb2z_uaVdaw-uPLK-9-SmI2JoP6EK7do-0" target="_blank" rel="noopener">블로그 Back-Propagation is very simple. Who made it Complicated ? </a>내용을 번역하여 소개하고자 한다.</p>
<div>
<img src="https://cdn-images-1.medium.com/max/2000/1*fnU_3MGmFp0LBIzRPx42-w.png">
<a style="display: block; text-align: center;" href="https://medium.com/@14prakash/back-propagation-is-very-simple-who-made-it-complicated-97b794c97e5c?fbclid=IwAR2bn8rI7yxT5BC-0Ovy2IvzHEb2z_uaVdaw-uPLK-9-SmI2JoP6EK7do-0" target="_blank" rel="noopener">출처 : [Medium] Back-Propagation is very simple. Who made it Complicated ?</a>
</div>

<h3 id="목차"><a href="#목차" class="headerlink" title="목차"></a>목차</h3><ul>
<li><a href="#nn-history">Neural Network 역사 및 Back propagation의 중요성</a></li>
<li><a href="#why-back-propagation">왜 Back propagation를 이해해야 할까?</a></li>
<li><a href="#back-propagation">Back Propagation 설명</a></li>
</ul>
<h3 id="nn-history" href="#nn-history">Neural Network 역사</h3>

<p> 1943년, 워런 맥컬록(Warren McCulloch)와 월터 피츠(Walter Pitts)의 수학과 임계 논리(Threshold logic)라 불리는 알고리즘을 바탕으로 신경망을 위한 계산한 모델이 만들어지며 신경망 연구의 초석을 닦으며 <strong>Neural Network</strong> 역사가 시작되었다.</p>
<p> 하지만, 1969년에 마빈 민스키(Marvin Minsky)와 시모어 페퍼트(Seymour Papert)에 의해 기계학습 논문이 발표된 후 침체되었는데, 그 이유는 두 가지였다.</p>
<ol>
<li><p>단층 신경망은 선형으로 분류하기 때문에 아래의 그림처럼 문제가 배타적 논리합 회로(XOR problem)인 경우에는 해결하지 못한다.</p>
<div>
<img src="https://cdn-images-1.medium.com/max/2000/0*qdRb80zUpJPtrbRD.">
<a style="display: block; text-align: center;" href="https://medium.com/@jayeshbahire/the-xor-problem-in-neural-networks-50006411840b" target="_blank" rel="noopener">
출처 : [Medium] Back-Propagation is very simple. Who made it Complicated ?</a>
</div>
</li>
<li><p>Computing power가 부족하다.</p>
</li>
</ol>
<p>위의 두 가지 문제점 외에도 가중치를 업데이트하기 위한 회로 수학 계산이 너무 복잡하였기에 <strong>오차역전파법(Back Propagation)</strong> 이 세상에 나오기 전까지는 연구가 침체될 수밖에 없었다.</p>
<h3 id="why-back-propagation" href="#why-back-propagation">왜 Back propagation를 이해해야 할까?</h3>

<p>“어차피 TensorFlow를 사용하면 다 자동으로 계산해주는 것인데 왜 우리가 공부해야 하는 것일까?”</p>
<p>합리적인 질문이다. 공식만 봐도 어려워보이는 이 부분을 공부하는 것이 동기부여가 쉽게 되지않는것이 사실이기 때문에..</p>
<p>하지만, <a href="https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b" target="_blank" rel="noopener">Yes you should understand backprop</a> 글에서 설명했듯 이 <strong>Back Propagation</strong> 은 <strong>Leaky Abstraction</strong> 라는 것이다.</p>
<blockquote>
<p><strong>Leaky Abstraction</strong><br><br>Joel Spolsky이 설명한 <a href="https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/" target="_blank" rel="noopener">The Law of Leaky Abstraction</a>에서 사용된 표현으로써 프로그래밍 언어를 추상화시켜서 내부 구현을 모르도록 만들어놨지만, <strong style="color:red">결국 제대로 사용하려면 내부 구현을 상당 부분 알아야 한다는 것을 의미한다.</strong></p>
</blockquote>
<p>이 포스트에서는 인공 신경망의 문제점에 대해서는 다루지 않기 때문에 왜 Leaky Abstraction이라 설명했는지 궁금한 경우에는 위의 블로그 링크를 참고하길 바란다.</p>
<h3 id="back-propagation" href="#back-propagation">Back Propagation</h3>

<h3 id="네트워크-초기화"><a href="#네트워크-초기화" class="headerlink" title="네트워크 초기화"></a>네트워크 초기화</h3><p><img src="/images/danial/back-prop/network.png"></p>
<script type="math/tex; mode=display">
Input = \left[ \begin{array}{cccc}
i_{1} \\ i_{2} \\\end{array} \right] W_{ji} = \left[ \begin{array}{cccc}
W_{j1i1} & W_{j1i2} \\
W_{j2i1} & W_{j2i2} \\
W_{j3i1} & W_{j3i2} \\ \end{array} \right]
W_{kj} = \left[ \begin{array}{cccc}
W_{k1j1} & W_{k1j2} & W_{k1j3} \\
W_{k2j1} & W_{k2j2} & W_{k2j3} \\
W_{k3j1} & W_{k3j2} & W_{k3j3} \\ \end{array} \right]
W_{ok} = \left[ \begin{array}{cccc}
W_{o1k1} & W_{o1k2} & W_{o1k3} \\
W_{o2k1} & W_{o2k2} & W_{o2k3} \\ \end{array} \right]
Output = \left[ \begin{array}{cccc}
o_{1} \\ o_{2} \\\end{array} \right]</script><h3 id="현재-이-포스트는-아직-미완상태입니다-최대한-빨리-완료해서-올리겠습니다-ㅠㅠ"><a href="#현재-이-포스트는-아직-미완상태입니다-최대한-빨리-완료해서-올리겠습니다-ㅠㅠ" class="headerlink" title="현재 이 포스트는 아직 미완상태입니다. 최대한 빨리 완료해서 올리겠습니다.ㅠㅠ"></a><span style="color: red;">현재 이 포스트는 아직 미완상태입니다. 최대한 빨리 완료해서 올리겠습니다.ㅠㅠ</span></h3><p>먼저 신경망의 계산 과정인 순방향 전파(Feedforward propagation)를 살펴보자.</p>
<h3 id="Layer-1-Input-gt-J"><a href="#Layer-1-Input-gt-J" class="headerlink" title="Layer 1 (Input -&gt; J)"></a>Layer 1 (Input -&gt; J)</h3><h3 id="Related-Posts"><a href="#Related-Posts" class="headerlink" title="Related Posts"></a>Related Posts</h3><p><a href="https://www.youtube.com/watch?v=tIeHLnjs5U8&amp;fbclid=IwAR2lsWOByt_MrzBkv5-Dc9P6JIdvHv1pUELE5q-0SVqQ73b6tS-RYGUI9eM" target="_blank" rel="noopener">Backpropagation calculus | Deep learning, chapter 4 by 3Blue1Brown</a><br><a href="https://datascienceschool.net/view-notebook/0178802a219c4e6bb9b820b49bf57f91/" target="_blank" rel="noopener">신경망 기초 이론</a></p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date tag-not-hover">2018-11-05</span><i class="fa fa-comment-o"></i><a href="/2018/11/05/Back-Propagation/#comments">Comments</a><!-- i.fas.fa-pencil-alt--><!-- a.tag(href=config.root + item.path, title= item.name)!= "Written by " + '<img class="post-footer-author" src="/images/avatar/' + png_name + '.png"> ' + item.name + " "--><a class="tag tag-not-hover">Written by <img class="post-footer-author" src="/images/avatar/danial-nam.png"> Danial Nam </a><br><i class="fa fa-tag"></i><!-- a.tag(href=config.root + item.path, title= item.name)= "#" + item.name + " "--><a class="tag tag-not-hover">#Artificial Intelligence </a><!-- a.tag(href=config.root + item.path, title= item.name)= "#" + item.name + " "--><a class="tag tag-not-hover">#Deep Learning </a><!-- a.tag(href=config.root + item.path, title= item.name)= "#" + item.name + " "--><a class="tag tag-not-hover">#Back Propagation </a><!-- a.tag(href=config.root + item.path, title= item.name)= "#" + item.name + " "--><a class="tag tag-not-hover">#Neural Network </a><div class="share-to-social">Share on <div class="sharer" id="sharer"> <div class="sharer-item" data-n="facebook"><i class="fab fa-facebook-f"></i></div><div class="sharer-item" data-n="twitter"><i class="fab fa-twitter"></i></div><div class="sharer-item" data-n="pinterest"><i class="fab fa-pinterest"></i></div></div></div></div></div></div></div><div class="share"></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2018/11/05/howto-stackedit/" title="Try StackEdit">Previous post</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2018/10/30/Basic-deep-learning-tensorflow-for-beginner-3/" title="&lt;Deep Learning&gt; An introduction to Deep Learning with Tensorflow(Part-3)">Next post</a></li></ul></div><a id="comments"></a><div id="disqus_thread"></div><script>var disqus_shortname = 'Databuzz';
var disqus_identifier = '2018/11/05/Back-Propagation/';
var disqus_title = '&lt;Neural Network&gt; 신경망 Feedforward &amp; Back Propagation에 대한 이해';
var disqus_url = 'https://databuzz-team.github.io/2018/11/05/Back-Propagation/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//#{theme.disqus}.disqus.com/count.js" async></script></div></div></div></div><a href="#" id="back-to-top" title="Back to top"><i class="fas fa-angle-up"></i></a></body></html>