<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Databuzz, Databuzz.team@gmail.com"><title><Deep Learning> An introduction to Deep Learning with Tensorflow(Part-3) · Databuzz's Tech Blog</title><!-- hexo-inject:begin --><!-- hexo-inject:end --><meta name="description" content="About

이번 포스트에서는 간단하게 회귀분석(Linear Regression) 의 개념과 Tensorflow 를 이용하여 학습하는 법에 대해서 알아보자.
목차
회귀분석(Regression Analysis)이란?
Tensorflow를 이용한 회귀 분석 실습
데이터 전"><meta name="keywords" content="DataScience"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta content="hA9pHsXOdxxbLoAhWc2b_3tvhy-58l3vHmH8dw3WVkA" name="google-site-verification"><meta name="renderer" content="webkit"><link rel="short icon" href="https://upload.wikimedia.org/wikipedia/commons/b/be/Normdist_regression.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/solid.css" integrity="sha384-VGP9aw4WtGH/uPAOseYxZ+Vz/vaTb1ehm1bwx92Fm8dTrE+3boLfF1SpAtB1z7HW" crossorigin="anonymous"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/fontawesome.css" integrity="sha384-1rquJLNOM3ijoueaaeS5m+McXPJCGdr5HcA03/VHXxcp2kX2sUrQDmFc3jR5i/C7" crossorigin="anonymous"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/brands.css" integrity="sha384-rf1bqOAj3+pw6NqYrtaE1/4Se2NBwkIfeYbsFdtiR6TQz0acWiwJbv1IM/Nt/ite" crossorigin="anonymous"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/fontawesome.css" integrity="sha384-1rquJLNOM3ijoueaaeS5m+McXPJCGdr5HcA03/VHXxcp2kX2sUrQDmFc3jR5i/C7" crossorigin="anonymous"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/reset.css"><link rel="stylesheet" href="/css/new.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Luckiest+Guy|Stylish|Boogaloo"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/js/jquery.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js"></script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-127200932-1"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/custom.js"></script><script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({ TeX: { extensions: ["color.js"] }});</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/main_logo_new.png" style="width:127px;"><h3 class="sidebar_title" title="">DataBuzz</h3><div class="description"><p class="title_description">Awesome Tech Blog<a class="rss-icon-a" href="https://databuzz-team.github.io/atom" target="__blank"><i class='fas fa-rss rss-icon'></i></a></p></div></div></div><div class="featured-tags-wrap"><h1 class="featured-tags-title">FEATURED TAGS</h1><ul class="featured-tags-ul"><li class="featured-tags-li tag-li-detail"> Machine Learning </li><li class="featured-tags-li tag-li-detail"> Data Science </li><li class="featured-tags-li tag-li-detail"> Hexo </li><li class="featured-tags-li tag-li-detail"> Mathjax </li><li class="featured-tags-li tag-li-detail"> Git </li><li class="featured-tags-li tag-li-detail"> Tech News </li><li class="featured-tags-li tag-li-detail"> Artificial Intelligence </li><li class="featured-tags-li tag-li-detail"> Deep Learning </li><li class="featured-tags-li tag-li-detail"> Tensorflow </li><li class="featured-tags-li tag-li-detail"> Catboost </li><li class="featured-tags-li tag-li-detail"> Regression </li><li class="featured-tags-li tag-li-detail"> Neural Network </li><li class="featured-tags-li tag-li-detail"> Scikit Learn </li><li class="featured-tags-li tag-li-detail"> Hyperparameter </li><li class="featured-tags-li tag-li-detail"> Portfolio </li><li class="featured-tags-li tag-li-detail"> Resume </li><li class="featured-tags-li tag-li-detail"> Back Propagation </li><li class="featured-tags-li tag-li-detail"> Markdown </li></ul></div><div class="footer"><span>@ 2018 DataBuzz All Rights Reserved</span><br><span>Hexo Theme by </span><a href="https://www.caicai.me"> CaiCai </a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><span>&nbsp;&nbsp;&nbsp; Edited by </span><a href="https://danialdaehyunnam.github.io"> Danial Nam </a></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/"><i class="fas fa-home nav-icon"></i>Home</a></li><li><a href="/archives"><i class="fas fa-archive nav-icon"></i>Archives</a></li><li><a href="/tags-and-authors"><i class="fas fa-user-tag nav-icon"></i>Tags & Authors</a></li><li><a href="/about-us"><i class="fas fa-building nav-icon"></i>About Us</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left back-btn-icon" onclick="window.history.go(-1)"> </a></li></div><div class="avatar"><img src="/images/sun.png"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>&lt;Deep Learning&gt; An introduction to Deep Learning with Tensorflow(Part-3)</a></h3></div><div class="post-content post-detail"><h3>About</h3>

<!-- hexo-inject:begin --><!-- hexo-inject:end --><p>이번 포스트에서는 간단하게 <strong>회귀분석(Linear Regression)</strong> 의 개념과 <strong>Tensorflow</strong> 를 이용하여 학습하는 법에 대해서 알아보자.</p>
<h4 id="목차"><a href="#목차" class="headerlink" title="목차"></a>목차</h4><ul>
<li><a href="#linear-regression">회귀분석(Regression Analysis)이란?</a></li>
<li><a href="#tensorflow-regression">Tensorflow를 이용한 회귀 분석 실습</a><ul>
<li><a href="#preprocessing">데이터 전처리(Data preprocessing)</a></li>
<li><a href="#tensorflow-regerssion-modeling">Tensorflow Modeling</a></li>
</ul>
</li>
<li><a href="#jupter-notebook">Jupyter Notebook</a></li>
</ul>
<h3 id="linear-regression" href="#linear-regression">회귀분석(Regression Analysis)이란?</h3>

<p>위키피디아의 정의에 의하면,</p>
<blockquote>
<p>통계학에서, 선형 회귀(linear regression)는 종속 변수 y와 한 개 이상의 독립 변수 (또는 설명 변수) X와의 선형 상관 관계를 모델링하는 회귀분석 기법이다.</p>
</blockquote>
<p>여기서 <strong>독립 변수</strong> 는 입력값이나 원인을 나타내며, <strong>종속 변수</strong> 는 결과물이나 효과를 나타낸다.</p>
<p>예) 집값을 예측하는 모델이라면 집값이 종속 변수(y)이고, 집의 위치, 방의 개수 등의 특징(Feature)들이 독립 변수(x)가 된다.</p>
<div>
<img src="https://upload.wikimedia.org/wikipedia/commons/b/be/Normdist_regression.png">
<p style="width: 100%; text-align:center;">
<a href="https://ko.wikipedia.org/wiki/%ED%9A%8C%EA%B7%80_%EB%B6%84%EC%84%9D" target="_blank" rel="noopener">출처 : 위키백과</a>
</p>
</div>

<p>위 그림은 독립 변수 1개와 종속 변수 1개를 가진 회귀 분석의 예이며, 그 중에서도 <strong>선형 회귀(Linear Regression)</strong> 를 한 예이다.</p>
<p>여기서 <strong>선형 회귀</strong> 에 대해서만 간단하게 소개하자면 가장 널리 사용되는 기법이며, 종속 변수와 독립 변수의 관계가 <strong>선형(Linear)</strong> 인 경우에 사용한다.</p>
<blockquote>
<p>회귀 분석 기법은 선형 회귀 외에도 다양한 종류가 있는데, 이 포스트에서 소개하지는 않을 예정이고, 나중에 <a href="https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/" target="_blank" rel="noopener">링크</a>의 내용을 번역하여 공유하도록 하겠다.(자세한 내용이 궁금한 사람은 위의 링크를 통해서 확인하자)</p>
</blockquote>
<h3 id="tensorflow-regression" href="#tensorflow-regression">Tensorflow를 이용한 회귀 분석 실습</h3>

<h4 id="preprocessing" href="#preprocessing">1. 데이터 전처리(Data preprocessing)</h4>

<blockquote>
<p>데이터 전처리는 이번 포스트의 주목적이 아니므로 자세한 설명을 더하진 않겠다.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import Dependencies</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line">boston = load_boston()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 독립 변수와 종속 변수를 분리한다.</span></span><br><span class="line">X_data = pd.DataFrame(boston.data, columns=boston.feature_names)</span><br><span class="line">y_data = pd.DataFrame(boston.target, columns=[<span class="string">"Target"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train Test 데이터를 분리한다</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># StandardScaler를 사용하여 스케일링한다</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 객체로 사용해야 나중에 Test데이터에 같은 Mean, Variance를 사용할 수 있다.</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">scaler.fit(X_train)</span><br><span class="line">X_train = pd.DataFrame(data=scaler.transform(X_train), columns=X_train.columns, index=X_train.index)</span><br><span class="line"><span class="comment"># 주의 : Test 데이터는 fit을하면 안된다! 객체 내부에 설정된 Mean, Variance값이 Update되기 때문에 여기서는 transform만 사용한다.</span></span><br><span class="line">X_test = pd.DataFrame(data=scaler.transform(X_test), columns=X_test.columns, index=X_test.index)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Tensorflow에서 사용할 땐 Numpy 데이터 타입으로 사용할 예정이니 변환하자</span></span><br><span class="line">X_train = np.array(X_train)</span><br><span class="line">y_train = np.array(y_train)</span><br><span class="line">X_test = np.array(X_test)</span><br><span class="line">y_test = np.array(y_test)</span><br><span class="line">type(X_train), type(y_train), type(X_test), type(y_test)</span><br></pre></td></tr></table></figure>
<p>이 예제에서는 Scaler로 <strong>StandardScaler(평균은 0으로, 표준편차는 1로 만드는 Scaler)</strong> 를 사용하였지만, 데이터마다 적절한 Scaler는 다를 수 있음을 명심하자. 역시 이 포스트에서는 자세히 다루지 않겠으며, 관심이 있는 사람들은 아래에 링크를 통해서 간략하게 이해를 하는 것을 추천한다.</p>
<ul>
<li><a href="http://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html" target="_blank" rel="noopener">Compare the effect of different scalers on data with outliers(Scikit-learn documentation)</a></li>
<li><a href="https://datascienceschool.net/view-notebook/f43be7d6515b48c0beb909826993c856/" target="_blank" rel="noopener">Scikit-Learn의 전처리 기능(데이터 사이언스 스쿨)</a></li>
</ul>
<p></p><h4 id="tensorflow-regerssion-modeling" href="#tensorflow-regerssion-modeling">2. Tensorflow Modeling</h4><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Learning Rate</span></span><br><span class="line">lr = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 가중치를 몇번 업데이트 할 것인가?</span></span><br><span class="line">epochs = <span class="number">2000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Features 독립 변수</span></span><br><span class="line">X = tf.placeholder(dtype=tf.float32, shape=[<span class="keyword">None</span>, X_train.shape[<span class="number">1</span>]])</span><br><span class="line"><span class="comment"># Labels 종속 변수</span></span><br><span class="line">y = tf.placeholder(dtype=tf.float32, shape=[<span class="keyword">None</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Weight 가중치, 초기값은 정규분포에서 랜덤하게 뽑는다</span></span><br><span class="line">W = tf.Variable(tf.random_normal([X_train.shape[<span class="number">1</span>], <span class="number">1</span>]))</span><br><span class="line"><span class="comment"># Bias 초기값은 정규분포에서 랜덤하게 뽑는다</span></span><br><span class="line">b = tf.Variable(tf.random_normal([<span class="number">1</span>]))</span><br></pre></td></tr></table></figure><p></p>
<p>여기서 <strong>placeholder()</strong> , <strong>Variable()</strong> 메서드 사용법에 대해서는 <a href="https://databuzz-team.github.io/2018/10/24/Basic-deep-learning-tensorflow-for-beginner-2/">이전 포스트</a>를 참고하자.  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tf.Variable을 사용했거나, 메서드 내부적으로 변수가 존재하는 경우에는 Variables</span></span><br><span class="line"><span class="comment"># 초기화해줘야 한다.</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 우리가 예측하는 값 W*X + b</span></span><br><span class="line">hypothesis = tf.add(tf.matmul(X, W), b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># cost function으로는 MSE를 사용</span></span><br><span class="line">cost = tf.reduce_mean(tf.square(y - hypothesis))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Gradient Descent 방법으로 최적화</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(cost)</span><br><span class="line"></span><br><span class="line"><span class="comment"># cost_history를 기록하면 마지막에 epoch 변화에 따른 cost 변화를 확인할 때 편리하다</span></span><br><span class="line">cost_history = np.empty(shape=[<span class="number">1</span>], dtype=float)</span><br></pre></td></tr></table></figure>
<p>이렇게 필요한 Graph는 다 만들었으니, 이제 Session을 열어서 W, b를 update하며 Cost Function의 값을 최소화하는 작업을 실행하자.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">0</span>, epochs):</span><br><span class="line">        <span class="comment"># optimizer에서 반환하는 값은 의미가 없으니 _로 받아주자</span></span><br><span class="line">        _, err = sess.run([optimizer, cost], feed_dict=&#123;X: X_train, y: y_train&#125;)</span><br><span class="line"></span><br><span class="line">        cost_history = np.append(cost_history, err)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 100 번에 한번씩 Error 변화를 확인하자</span></span><br><span class="line">        <span class="keyword">if</span> epoch%<span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'Epoch: &#123;0&#125;, Error: &#123;1&#125;'</span>.format(epoch, err))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'Epoch: &#123;0&#125;, Error: &#123;1&#125;'</span>.format(epoch + <span class="number">1</span>, err))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 우리가 설정한 Epochs만큼의 학습이 끝난 후에 나온 값을 확인하기 위해 받아두자</span></span><br><span class="line">    updated_W = sess.run(W)</span><br><span class="line">    updated_b = sess.run(b)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Test 데이터를 예측한 값</span></span><br><span class="line">    y_pred = sess.run(hypothesis, feed_dict=&#123;X: X_test&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Mean Squared Error</span></span><br><span class="line">    mse = sess.run(tf.reduce_mean(tf.square(y_pred - y_test)))</span><br></pre></td></tr></table></figure></p>
<p>위의 코드들을 통해서 <strong>Tensorflow Session</strong> 을 이용하여 <strong>회귀 분석(Regression Analysis)</strong> 방법을 알아보았고, 아래에 <strong>Jupyter notebook</strong> 에서는 <strong>Tensorflow</strong> 이 제공하는 <strong>Estimator API</strong> 를 사용하여 <strong>Linear Regression</strong> 하는 방법도 추가되어 있으니 도움이 되길 바란다.</p>
<h3 id="jupter-notebook" href="#jupter-notebook">Jupyter Notebook</h3>

<div class="notebook-embedded">
<iframe src="https://nbviewer.jupyter.org/gist/DanialDaeHyunNam/6d96c11ac99bc2f2413ca5c8c6490dbc" width="100%" height="100%" frameborder="0" allowfullscreen></iframe>
</div>

<p>이 다음 포스트에서는 <strong>Tensorflow</strong> 로 <strong>인공 신경망(Neural Network)</strong> 을 구현하는 법에 대해서 작성하겠다.</p>
<h3 id="Related-Posts"><a href="#Related-Posts" class="headerlink" title="Related Posts"></a>Related Posts</h3><ul>
<li><a href="http://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html" target="_blank" rel="noopener">Compare the effect of different scalers on data with outliers(Scikit-learn documentation)</a></li>
<li><a href="https://datascienceschool.net/view-notebook/f43be7d6515b48c0beb909826993c856/" target="_blank" rel="noopener">Scikit-Learn의 전처리 기능(데이터 사이언스 스쿨)</a></li>
</ul>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date tag-not-hover">2018-10-30</span><i class="fa fa-comment-o"></i><a href="/2018/10/30/Basic-deep-learning-tensorflow-for-beginner-3/#comments">Comments</a><!-- i.fas.fa-pencil-alt--><!-- a.tag(href=config.root + item.path, title= item.name)!= "Written by " + '<img class="post-footer-author" src="/images/avatar/' + png_name + '.png"> ' + item.name + " "--><a class="tag tag-not-hover">Written by <img class="post-footer-author" src="/images/avatar/danial-nam.png"> Danial Nam </a><br><i class="fa fa-tag"></i><!-- a.tag(href=config.root + item.path, title= item.name)= "#" + item.name + " "--><a class="tag tag-not-hover">#Machine Learning </a><!-- a.tag(href=config.root + item.path, title= item.name)= "#" + item.name + " "--><a class="tag tag-not-hover">#Data Science </a><!-- a.tag(href=config.root + item.path, title= item.name)= "#" + item.name + " "--><a class="tag tag-not-hover">#Tensorflow </a><!-- a.tag(href=config.root + item.path, title= item.name)= "#" + item.name + " "--><a class="tag tag-not-hover">#Regression </a><div class="share-to-social">Share on <div class="sharer" id="sharer"> <div class="sharer-item" data-n="facebook"><i class="fab fa-facebook-f"></i></div><div class="sharer-item" data-n="twitter"><i class="fab fa-twitter"></i></div><div class="sharer-item" data-n="pinterest"><i class="fab fa-pinterest"></i></div></div></div></div></div></div></div><div class="share"></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2018/11/05/Back-Propagation/" title="&lt;Neural Network&gt; 인공신경망에 대한 이해(Part 1 - Feedforward Propagation)">Previous post</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2018/10/24/Catboost/" title="&lt;MACHINE LEARNING&gt;Catboost 알아보기">Next post</a></li></ul></div><a id="comments"></a><div id="disqus_thread"></div><script>var disqus_shortname = 'Databuzz';
var disqus_identifier = '2018/10/30/Basic-deep-learning-tensorflow-for-beginner-3/';
var disqus_title = '&lt;Deep Learning&gt; An introduction to Deep Learning with Tensorflow(Part-3)';
var disqus_url = 'https://databuzz-team.github.io/2018/10/30/Basic-deep-learning-tensorflow-for-beginner-3/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//#{theme.disqus}.disqus.com/count.js" async></script></div></div></div></div><a href="#" id="back-to-top" title="Back to top"><i class="fas fa-angle-up"></i></a><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>